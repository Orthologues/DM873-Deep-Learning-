{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fefb07a9",
   "metadata": {},
   "source": [
    "## Step 0. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8bae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import *\n",
    "import utils\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
    "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from statistics import mean\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bbd8fa",
   "metadata": {},
   "source": [
    "## Step 1. Examine and load the test/train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fc83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2146e66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jiz/Downloads/DeepLearning/test_encoded.zip\n",
      "/Users/jiz/Downloads/DeepLearning/train.zip\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls /Users/jiz/Downloads/DeepLearning/*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "972ecf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mv /Users/jiz/Downloads/DeepLearning/*.zip raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4227b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls raw_data/*.zip|while read zipf; do\n",
    "    unzip $zipf >> /dev/null 2>&1\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a132fc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX\n",
      "kerasLayers_Test.ipynb\n",
      "raw_data\n",
      "test_encoded\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42c1fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL\n",
      "PNEUMONIA\n",
      "\n",
      "\n",
      "NORMAL\n",
      "PNEUMONIA\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls test_encoded/\n",
    "echo -e \"\\n\"\n",
    "ls train/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e47e7",
   "metadata": {},
   "source": [
    "### Obtain the size of training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fea8546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_encoded\n",
      "NORMAL\n",
      "      30\n",
      "PNEUMONIA\n",
      "      21\n",
      "train\n",
      "NORMAL\n",
      "    1341\n",
      "PNEUMONIA\n",
      "    1341\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"test_encoded\"\n",
    "ls test_encoded/|while read class; do \n",
    "    echo $class && ls test_encoded/$class|wc -l\n",
    "done\n",
    "\n",
    "echo \"train\"\n",
    "ls train/|while read class; do\n",
    "    echo $class && ls train/$class|wc -l\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d14220",
   "metadata": {},
   "source": [
    "### Obtain the format of training/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a4c29f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/NORMAL/IM-0115-0001.jpeg\n",
      "train/NORMAL/IM-0117-0001.jpeg\n",
      "train/NORMAL/IM-0119-0001.jpeg\n",
      "train/NORMAL/IM-0122-0001.jpeg\n",
      "train/NORMAL/IM-0125-0001.jpeg\n",
      "train/PNEUMONIA/person1000_bacteria_2931.jpeg\n",
      "train/PNEUMONIA/person1001_bacteria_2932.jpeg\n",
      "train/PNEUMONIA/person1002_bacteria_2933.jpeg\n",
      "train/PNEUMONIA/person1004_bacteria_2935.jpeg\n",
      "train/PNEUMONIA/person1005_bacteria_2936.jpeg\n",
      "train/PNEUMONIA/person1006_bacteria_2937.jpeg\n",
      "train/PNEUMONIA/person1007_bacteria_2938.jpeg\n",
      "train/PNEUMONIA/person1010_bacteria_2941.jpeg\n",
      "train/PNEUMONIA/person1011_bacteria_2942.jpeg\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls train/NORMAL/*|head -n5\n",
    "ls train/PNEUMONIA/*|head -n9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e46b1a",
   "metadata": {},
   "source": [
    "### Visualize the train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac0aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_top9_imgs: List[str] = [\n",
    "    \"train/PNEUMONIA/person1000_bacteria_2931.jpeg\",\n",
    "    \"train/PNEUMONIA/person1001_bacteria_2932.jpeg\",\n",
    "    \"train/PNEUMONIA/person1002_bacteria_2933.jpeg\",\n",
    "    \"train/PNEUMONIA/person1004_bacteria_2935.jpeg\",\n",
    "    \"train/PNEUMONIA/person1005_bacteria_2936.jpeg\",\n",
    "    \"train/PNEUMONIA/person1006_bacteria_2937.jpeg\",\n",
    "    \"train/PNEUMONIA/person1007_bacteria_2938.jpeg\",\n",
    "    \"train/PNEUMONIA/person1010_bacteria_2941.jpeg\",\n",
    "    \"train/PNEUMONIA/person1011_bacteria_2942.jpeg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f15df6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define location of dataset\n",
    "pneumonia_folder = 'train/PNEUMONIA'\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(3, 3, i+1)\n",
    "    # define filename\n",
    "    filename = pneumonia_top9_imgs[i]\n",
    "    # load image pixels\n",
    "    image = imread(filename)\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "323f0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_encoded/NORMAL/_0_793163.txt\n",
      "test_encoded/NORMAL/_10_2309560.txt\n",
      "test_encoded/NORMAL/_10_4614217.txt\n",
      "test_encoded/NORMAL/_11_2646888.txt\n",
      "test_encoded/NORMAL/_12_3260859.txt\n",
      "test_encoded/PNEUMONIA/_0_2894513.txt\n",
      "test_encoded/PNEUMONIA/_11_7509739.txt\n",
      "test_encoded/PNEUMONIA/_12_7226461.txt\n",
      "test_encoded/PNEUMONIA/_13_8376919.txt\n",
      "test_encoded/PNEUMONIA/_14_4289383.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls test_encoded/NORMAL/*|head -n5\n",
    "ls test_encoded/PNEUMONIA/*|head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e570c6",
   "metadata": {},
   "source": [
    "### Test a glimpse at how the test <code>.txt</code> files would actually look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afde1c23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.900000000000000000e+01 3.900000000000000000e+01 4.800000000000000000e+01 4.600000000000000000e+01 5.100000000000000000e+01 9.300000000000000000e+01 1.170000000000000000e+02 9.400000000000000000e+01 8.600000000000000000e+01 8.700000000000000000e+01 8.300000000000000000e+01 8.900000000000000000e+01 8.600000000000000000e+01 9.500000000000000000e+01 9.900000000000000000e+01 1.210000000000000000e+02 1.250000000000000000e+02 9.100000000000000000e+01 6.300000000000000000e+01 6.300000000000000000e+01 6.000000000000000000e+01 6.500000000000000000e+01 5.900000000000000000e+01 5.400000000000000000e+01 5.800000000000000000e+01 5.500000000000000000e+01 5.800000000000000000e+01 5.600000000000000000e+01 6.000000000000000000e+01 5.500000000000000000e+01 5.500000000000000000e+01 5.700000000000000000e+01 5.700000000000000000e+01 5.800000000000000000e+01 5.200000000000000000e+01 4.700000000000000000e+01 4.600000000000000000e+01 4.200000000000000000e+01 3.600000000000000000e+01 3.000000000000000000e+01 2.800000000000000000e+01 2.700000000000000000e+01 2.400000000000000000e+01 1.900000000000000000e+01 1.500000000000000000e+01 7.000000000000000000e+00 1.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 7.000000000000000000e+00 1.600000000000000000e+01 2.600000000000000000e+01 2.800000000000000000e+01 3.000000000000000000e+01 3.400000000000000000e+01 5.800000000000000000e+01 7.700000000000000000e+01 9.300000000000000000e+01 9.700000000000000000e+01 1.090000000000000000e+02 1.100000000000000000e+02 1.190000000000000000e+02 1.540000000000000000e+02 1.700000000000000000e+02 1.670000000000000000e+02 1.610000000000000000e+02 1.510000000000000000e+02 1.650000000000000000e+02 1.640000000000000000e+02 1.710000000000000000e+02 1.700000000000000000e+02 1.780000000000000000e+02 2.000000000000000000e+02 1.920000000000000000e+02 1.840000000000000000e+02 1.830000000000000000e+02 1.780000000000000000e+02 1.730000000000000000e+02 1.640000000000000000e+02 1.640000000000000000e+02 1.750000000000000000e+02 1.780000000000000000e+02 1.780000000000000000e+02 1.880000000000000000e+02 1.850000000000000000e+02 1.890000000000000000e+02 1.910000000000000000e+02 1.930000000000000000e+02 1.870000000000000000e+02 1.920000000000000000e+02 1.910000000000000000e+02 1.840000000000000000e+02 1.850000000000000000e+02 1.860000000000000000e+02 1.740000000000000000e+02 1.720000000000000000e+02 1.790000000000000000e+02 1.820000000000000000e+02 1.870000000000000000e+02 1.840000000000000000e+02 1.930000000000000000e+02 1.920000000000000000e+02 1.910000000000000000e+02 1.880000000000000000e+02 1.840000000000000000e+02 1.930000000000000000e+02 1.910000000000000000e+02 1.780000000000000000e+02 1.840000000000000000e+02 1.760000000000000000e+02 1.780000000000000000e+02 1.680000000000000000e+02 1.780000000000000000e+02 1.910000000000000000e+02 1.910000000000000000e+02 1.890000000000000000e+02 1.760000000000000000e+02 1.800000000000000000e+02 1.740000000000000000e+02 1.890000000000000000e+02 1.920000000000000000e+02 1.960000000000000000e+02 1.720000000000000000e+02 1.470000000000000000e+02 1.450000000000000000e+02 1.440000000000000000e+02 1.390000000000000000e+02 1.390000000000000000e+02 1.410000000000000000e+02 1.370000000000000000e+02 1.360000000000000000e+02 1.270000000000000000e+02 1.320000000000000000e+02 1.310000000000000000e+02 1.270000000000000000e+02 1.230000000000000000e+02 1.180000000000000000e+02 1.130000000000000000e+02 1.050000000000000000e+02 9.200000000000000000e+01 8.400000000000000000e+01 7.900000000000000000e+01 7.700000000000000000e+01 7.200000000000000000e+01 7.700000000000000000e+01 7.800000000000000000e+01 6.500000000000000000e+01 3.600000000000000000e+01 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 2.200000000000000000e+01 3.700000000000000000e+01 3.700000000000000000e+01 4.200000000000000000e+01 4.900000000000000000e+01 6.200000000000000000e+01 6.800000000000000000e+01 7.600000000000000000e+01 7.800000000000000000e+01 8.300000000000000000e+01 8.400000000000000000e+01 8.500000000000000000e+01 8.700000000000000000e+01 8.400000000000000000e+01 9.300000000000000000e+01 9.300000000000000000e+01 9.100000000000000000e+01 8.900000000000000000e+01 8.900000000000000000e+01 9.000000000000000000e+01 9.100000000000000000e+01 9.100000000000000000e+01 8.200000000000000000e+01 8.700000000000000000e+01 8.700000000000000000e+01 8.500000000000000000e+01 8.300000000000000000e+01 7.600000000000000000e+01 7.900000000000000000e+01 1.070000000000000000e+02 1.420000000000000000e+02 1.350000000000000000e+02 1.110000000000000000e+02 1.080000000000000000e+02 1.110000000000000000e+02 1.150000000000000000e+02 1.050000000000000000e+02 1.020000000000000000e+02 1.010000000000000000e+02 1.070000000000000000e+02 1.040000000000000000e+02 1.110000000000000000e+02 1.280000000000000000e+02 1.500000000000000000e+02 8.100000000000000000e+01 7.900000000000000000e+01 8.400000000000000000e+01 8.200000000000000000e+01 7.900000000000000000e+01 6.900000000000000000e+01 7.100000000000000000e+01 7.100000000000000000e+01 6.900000000000000000e+01 6.700000000000000000e+01 6.200000000000000000e+01 5.000000000000000000e+01 4.200000000000000000e+01 3.800000000000000000e+01 3.900000000000000000e+01 4.900000000000000000e+01 7.400000000000000000e+01 1.030000000000000000e+02\n",
      "     224 test_encoded/NORMAL/_0_793163.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cat test_encoded/NORMAL/_0_793163.txt|head -n1\n",
    "wc -l test_encoded/NORMAL/_0_793163.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a861f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     224\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -n1 test_encoded/NORMAL/_0_793163.txt|tr \" \" \"\\n\"|wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df0aa5",
   "metadata": {},
   "source": [
    "### As a conclusion, each test <code>.txt</code> file represents a one-channel image at a resolution of 224x2224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe8bb95",
   "metadata": {},
   "source": [
    "### Therefore, we would have to write a function to read train and test images from OS using either <hr /><code>ImageDataGenerator</code> or <code>numpy.array</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbbf1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the image\n",
    "Image_Width=224\n",
    "Image_Height=224\n",
    "Batch_Size = 32\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b614be0",
   "metadata": {},
   "source": [
    "returns to a tuple of two ImageDataIterators, which consists of the augmented train iterator and the non-augmented test iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cbf7e6",
   "metadata": {},
   "source": [
    "A tutorial for <code>ImageDataGenerator.flow</code> to generate an ImageDataFlow from Numpy arrays: https://theailearner.com/2019/07/06/imagedatagenerator-flow-method/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c26cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_data(\n",
    "    input_path:str=\"\", \n",
    "    img_width:int=Image_Width, img_height:int=Image_Height, img_channels:int=Image_Channels,\n",
    "    batch_size:int=Batch_Size\n",
    ") -> Tuple[any]:\n",
    "    \n",
    "    # input parameter assertions\n",
    "    assert img_width >= 16 and img_height>=16\n",
    "    assert img_channels in {1, 3, 4}\n",
    "    assert 16<=batch_size<=256\n",
    "    \n",
    "    # ImageDataGenerator objects\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        rotation_range=45, fill_mode='nearest', \n",
    "        brightness_range = (0.8, 1.25),\n",
    "        zoom_range= (0.8, 1.25),\n",
    "        width_shift_range=0.2, height_shift_range=0.2,\n",
    "        channel_shift_range=50\n",
    "    )\n",
    "    \n",
    "    # only rescaling\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # This is fed to the network in the specified batch sizes and image dimensions\n",
    "    train_iterator = train_datagen.flow_from_directory(\n",
    "        directory=input_path+'train', \n",
    "        target_size=(img_width, img_height), \n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary', \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # I will be making predictions off of the test set in one batch size\n",
    "    # This is useful to be able to get the confusion matrix\n",
    "    test_data: List[np.ndarray] = []\n",
    "    test_labels: List[int] = []\n",
    "\n",
    "    for cond in ('/NORMAL/', '/PNEUMONIA/'):\n",
    "        for img_fname in (os.listdir(f\"{input_path}test_encoded{cond}\")):\n",
    "            \"\"\"\n",
    "            Reads the text files into numpy arrays.\n",
    "            PNG images are returned as float arrays (0-1). \n",
    "            All other formats are returned as int arrays, with a bit depth determined by the file's contents.\n",
    "            \"\"\"\n",
    "            txt_fname = f\"{input_path}test_encoded{cond}{img_fname}\"\n",
    "            raw_img_array = pd.read_csv(txt_fname, header=None, sep=\" \").to_numpy()\n",
    "            greyscale_img_array = cv2.resize(raw_img_array, (img_width, img_height))\n",
    "            # converts one-channel images into three channel images\n",
    "            rgb_img_array = cv2.merge([greyscale_img_array]*3)\n",
    "            rgb_img_array = rgb_img_array.astype('float32')\n",
    "            label = 0 if cond==\"/NORMAL/\" else 1\n",
    "            test_data.append(rgb_img_array)\n",
    "            test_labels.append(label)\n",
    "        \n",
    "    test_data = np.array(test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    test_iterator = test_datagen.flow(\n",
    "        test_data, test_labels, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    return train_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1bb6981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2682 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_iterator, test_iterator = process_input_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ac9564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.preprocessing.image.DirectoryIterator'> <class 'keras.preprocessing.image.NumpyArrayIterator'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_iterator), type(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13540224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL/IM-0115-0001.jpeg', 'NORMAL/IM-0117-0001.jpeg', 'NORMAL/IM-0119-0001.jpeg'] ['PNEUMONIA/person998_bacteria_2927.jpeg', 'PNEUMONIA/person9_bacteria_38.jpeg', 'PNEUMONIA/person9_bacteria_39.jpeg'] 2682\n"
     ]
    }
   ],
   "source": [
    "print(train_iterator.filenames[:3], train_iterator.filenames[-3:], len(train_iterator.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ffedf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0] [1 1 1] 2682\n"
     ]
    }
   ],
   "source": [
    "print(train_iterator.labels[:3], train_iterator.labels[-3:], len(train_iterator.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a94c0d",
   "metadata": {},
   "source": [
    "Therefore, we could know that Normal=0 and Pneumonia=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5f0f5",
   "metadata": {},
   "source": [
    "## Step 2. Train and test a CNN model that directly uses objects at <code>keras.layers.*</code> \n",
    "This test is only for test due to the ban on using predefined layers, we would have to write our own layers using <code>keras.backend</code> later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28cdb309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 222, 222, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 109, 109, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 52, 52, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               18874880  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,265,729\n",
      "Trainable params: 19,264,769\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define the CNN model with 92% accuracy that we used in the Dog VS Cat Project\n",
    "Returns to tf.keras.Sequential\n",
    "\"\"\"\n",
    "\n",
    "def create_CNN_Model(Image_size: tuple, Image_channels=3) -> tf.keras.Sequential:\n",
    "    assert len(Image_Size)==2 and Image_Size[0]>0 and Image_Size[1]>0, \"Image_size must be a tuple of two positive integers!\"\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32,(3,3),activation='relu', kernel_initializer=keras.initializers.he_uniform(seed=42), input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64,(3,3), kernel_initializer=keras.initializers.he_uniform(seed=42), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128,(3,3), kernel_initializer=keras.initializers.he_uniform(seed=42), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(256,(3,3), kernel_initializer=keras.initializers.he_uniform(seed=42), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512,activation='relu', kernel_regularizer=keras.regularizers.L2(5e-3)))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "model = create_CNN_Model(Image_size=Image_Size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93ee0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitted_model(model: Sequential, lr: float, train_imgs: keras.preprocessing.image.DirectoryIterator, val_imgs: keras.preprocessing.image.NumpyArrayIterator) -> Tuple:\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='weights.best.inc.blond.hdf5', verbose=1, save_best_only=True)\n",
    "    model_history = model.fit(train_imgs, validation_data=val_imgs, steps_per_epoch=len(train_imgs), validation_steps=len(val_imgs), epochs=10, callbacks=[checkpointer])\n",
    "    return (model, model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a57b11d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 10.1324 - accuracy: 0.7994\n",
      "Epoch 1: val_loss improved from inf to 16.46479, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 46s 543ms/step - loss: 10.1324 - accuracy: 0.7994 - val_loss: 16.4648 - val_accuracy: 0.4118\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 3.1712 - accuracy: 0.8594\n",
      "Epoch 2: val_loss did not improve from 16.46479\n",
      "84/84 [==============================] - 35s 415ms/step - loss: 3.1712 - accuracy: 0.8594 - val_loss: 20.4864 - val_accuracy: 0.4118\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 2.0230 - accuracy: 0.8501\n",
      "Epoch 3: val_loss did not improve from 16.46479\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 2.0230 - accuracy: 0.8501 - val_loss: 24.4271 - val_accuracy: 0.4118\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 2.3946 - accuracy: 0.8494\n",
      "Epoch 4: val_loss improved from 16.46479 to 14.58795, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 2.3946 - accuracy: 0.8494 - val_loss: 14.5879 - val_accuracy: 0.4118\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 2.0125 - accuracy: 0.8680\n",
      "Epoch 5: val_loss improved from 14.58795 to 8.13072, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 2.0125 - accuracy: 0.8680 - val_loss: 8.1307 - val_accuracy: 0.4118\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.3500 - accuracy: 0.8669\n",
      "Epoch 6: val_loss improved from 8.13072 to 7.22014, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 1.3500 - accuracy: 0.8669 - val_loss: 7.2201 - val_accuracy: 0.4118\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 2.2422 - accuracy: 0.8628\n",
      "Epoch 7: val_loss improved from 7.22014 to 2.34920, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 2.2422 - accuracy: 0.8628 - val_loss: 2.3492 - val_accuracy: 0.7451\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.6516 - accuracy: 0.8751\n",
      "Epoch 8: val_loss improved from 2.34920 to 1.63685, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 1.6516 - accuracy: 0.8751 - val_loss: 1.6368 - val_accuracy: 0.6863\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.2317 - accuracy: 0.8788\n",
      "Epoch 9: val_loss improved from 1.63685 to 1.46206, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 1.2317 - accuracy: 0.8788 - val_loss: 1.4621 - val_accuracy: 0.6471\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.0779 - accuracy: 0.8826\n",
      "Epoch 10: val_loss did not improve from 1.46206\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 1.0779 - accuracy: 0.8826 - val_loss: 2.5155 - val_accuracy: 0.6078\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.6802 - accuracy: 0.8632\n",
      "Epoch 1: val_loss improved from inf to 1.72145, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 1.6802 - accuracy: 0.8632 - val_loss: 1.7214 - val_accuracy: 0.8627\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.4760 - accuracy: 0.8620\n",
      "Epoch 2: val_loss did not improve from 1.72145\n",
      "84/84 [==============================] - 41s 483ms/step - loss: 1.4760 - accuracy: 0.8620 - val_loss: 2.3542 - val_accuracy: 0.6863\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.6400 - accuracy: 0.8688\n",
      "Epoch 3: val_loss did not improve from 1.72145\n",
      "84/84 [==============================] - 35s 414ms/step - loss: 1.6400 - accuracy: 0.8688 - val_loss: 1.7888 - val_accuracy: 0.5490\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.2822 - accuracy: 0.8855\n",
      "Epoch 4: val_loss did not improve from 1.72145\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 1.2822 - accuracy: 0.8855 - val_loss: 1.9395 - val_accuracy: 0.5686\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.2364 - accuracy: 0.8889\n",
      "Epoch 5: val_loss improved from 1.72145 to 1.56879, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 1.2364 - accuracy: 0.8889 - val_loss: 1.5688 - val_accuracy: 0.7255\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.0856 - accuracy: 0.8915\n",
      "Epoch 6: val_loss did not improve from 1.56879\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 1.0856 - accuracy: 0.8915 - val_loss: 1.9040 - val_accuracy: 0.6275\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.8607 - accuracy: 0.8993\n",
      "Epoch 7: val_loss improved from 1.56879 to 1.40828, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.8607 - accuracy: 0.8993 - val_loss: 1.4083 - val_accuracy: 0.5882\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7621 - accuracy: 0.9016\n",
      "Epoch 8: val_loss improved from 1.40828 to 1.16069, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.7621 - accuracy: 0.9016 - val_loss: 1.1607 - val_accuracy: 0.6078\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.9027\n",
      "Epoch 9: val_loss did not improve from 1.16069\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.6936 - accuracy: 0.9027 - val_loss: 1.4016 - val_accuracy: 0.4118\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.9101\n",
      "Epoch 10: val_loss improved from 1.16069 to 0.93056, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.5763 - accuracy: 0.9101 - val_loss: 0.9306 - val_accuracy: 0.6471\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6190 - accuracy: 0.9049\n",
      "Epoch 1: val_loss improved from inf to 1.03026, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 417ms/step - loss: 0.6190 - accuracy: 0.9049 - val_loss: 1.0303 - val_accuracy: 0.7647\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7353 - accuracy: 0.9042\n",
      "Epoch 2: val_loss did not improve from 1.03026\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 0.7353 - accuracy: 0.9042 - val_loss: 1.0694 - val_accuracy: 0.6863\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.9120\n",
      "Epoch 3: val_loss improved from 1.03026 to 0.89988, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 0.6653 - accuracy: 0.9120 - val_loss: 0.8999 - val_accuracy: 0.7255\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.9150\n",
      "Epoch 4: val_loss did not improve from 0.89988\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.6788 - accuracy: 0.9150 - val_loss: 1.4732 - val_accuracy: 0.4118\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.9221\n",
      "Epoch 5: val_loss did not improve from 0.89988\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 0.5144 - accuracy: 0.9221 - val_loss: 1.1118 - val_accuracy: 0.6863\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.9124\n",
      "Epoch 6: val_loss did not improve from 0.89988\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.5461 - accuracy: 0.9124 - val_loss: 1.0230 - val_accuracy: 0.5882\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.9321\n",
      "Epoch 7: val_loss did not improve from 0.89988\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.4312 - accuracy: 0.9321 - val_loss: 3.1778 - val_accuracy: 0.5882\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.9273\n",
      "Epoch 8: val_loss did not improve from 0.89988\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.3393 - accuracy: 0.9273 - val_loss: 1.4286 - val_accuracy: 0.5882\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.9232\n",
      "Epoch 9: val_loss did not improve from 0.89988\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.3831 - accuracy: 0.9232 - val_loss: 2.3402 - val_accuracy: 0.4706\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3252 - accuracy: 0.9318\n",
      "Epoch 10: val_loss did not improve from 0.89988\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.3252 - accuracy: 0.9318 - val_loss: 0.9305 - val_accuracy: 0.6667\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.9314\n",
      "Epoch 1: val_loss improved from inf to 0.63486, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.3118 - accuracy: 0.9314 - val_loss: 0.6349 - val_accuracy: 0.8039\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.9400\n",
      "Epoch 2: val_loss improved from 0.63486 to 0.41197, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.2787 - accuracy: 0.9400 - val_loss: 0.4120 - val_accuracy: 0.8039\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.9340\n",
      "Epoch 3: val_loss did not improve from 0.41197\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.2902 - accuracy: 0.9340 - val_loss: 1.5865 - val_accuracy: 0.4118\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.9269\n",
      "Epoch 4: val_loss did not improve from 0.41197\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.3349 - accuracy: 0.9269 - val_loss: 0.7837 - val_accuracy: 0.7059\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.9355\n",
      "Epoch 5: val_loss did not improve from 0.41197\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.2931 - accuracy: 0.9355 - val_loss: 1.1571 - val_accuracy: 0.4706\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.9325\n",
      "Epoch 6: val_loss did not improve from 0.41197\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.2903 - accuracy: 0.9325 - val_loss: 0.8820 - val_accuracy: 0.5882\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2634 - accuracy: 0.9403\n",
      "Epoch 7: val_loss did not improve from 0.41197\n",
      "84/84 [==============================] - 44s 527ms/step - loss: 0.2634 - accuracy: 0.9403 - val_loss: 0.9247 - val_accuracy: 0.5294\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.9385\n",
      "Epoch 8: val_loss did not improve from 0.41197\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.2636 - accuracy: 0.9385 - val_loss: 0.5533 - val_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9426\n",
      "Epoch 9: val_loss did not improve from 0.41197\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.2612 - accuracy: 0.9426 - val_loss: 0.9446 - val_accuracy: 0.3725\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9385\n",
      "Epoch 10: val_loss did not improve from 0.41197\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 0.2571 - accuracy: 0.9385 - val_loss: 0.5783 - val_accuracy: 0.7647\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.9448\n",
      "Epoch 1: val_loss improved from inf to 0.60998, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 432ms/step - loss: 0.2419 - accuracy: 0.9448 - val_loss: 0.6100 - val_accuracy: 0.8039\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.9485\n",
      "Epoch 2: val_loss improved from 0.60998 to 0.57740, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.2354 - accuracy: 0.9485 - val_loss: 0.5774 - val_accuracy: 0.8039\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.9422\n",
      "Epoch 3: val_loss did not improve from 0.57740\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.2540 - accuracy: 0.9422 - val_loss: 2.5570 - val_accuracy: 0.5882\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.9381\n",
      "Epoch 4: val_loss improved from 0.57740 to 0.53549, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.2758 - accuracy: 0.9381 - val_loss: 0.5355 - val_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9463\n",
      "Epoch 5: val_loss did not improve from 0.53549\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.2349 - accuracy: 0.9463 - val_loss: 0.6873 - val_accuracy: 0.7059\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9467\n",
      "Epoch 6: val_loss did not improve from 0.53549\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 0.2423 - accuracy: 0.9467 - val_loss: 3.8927 - val_accuracy: 0.5882\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.9381\n",
      "Epoch 7: val_loss did not improve from 0.53549\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.2593 - accuracy: 0.9381 - val_loss: 1.5358 - val_accuracy: 0.6078\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.9392\n",
      "Epoch 8: val_loss improved from 0.53549 to 0.47837, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.2522 - accuracy: 0.9392 - val_loss: 0.4784 - val_accuracy: 0.8039\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.9463\n",
      "Epoch 9: val_loss did not improve from 0.47837\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.2434 - accuracy: 0.9463 - val_loss: 1.4355 - val_accuracy: 0.6078\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.9355\n",
      "Epoch 10: val_loss did not improve from 0.47837\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.2595 - accuracy: 0.9355 - val_loss: 1.1635 - val_accuracy: 0.5882\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9508\n",
      "Epoch 1: val_loss improved from inf to 1.00043, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.2221 - accuracy: 0.9508 - val_loss: 1.0004 - val_accuracy: 0.6275\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9556\n",
      "Epoch 2: val_loss improved from 1.00043 to 0.53744, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.1962 - accuracy: 0.9556 - val_loss: 0.5374 - val_accuracy: 0.7647\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9646\n",
      "Epoch 3: val_loss did not improve from 0.53744\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.1652 - accuracy: 0.9646 - val_loss: 0.6259 - val_accuracy: 0.7843\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.9620\n",
      "Epoch 4: val_loss did not improve from 0.53744\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.1590 - accuracy: 0.9620 - val_loss: 1.2423 - val_accuracy: 0.6863\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9597\n",
      "Epoch 5: val_loss improved from 0.53744 to 0.50363, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.1622 - accuracy: 0.9597 - val_loss: 0.5036 - val_accuracy: 0.8431\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9616\n",
      "Epoch 6: val_loss improved from 0.50363 to 0.40742, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 0.1547 - accuracy: 0.9616 - val_loss: 0.4074 - val_accuracy: 0.8431\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9627\n",
      "Epoch 7: val_loss improved from 0.40742 to 0.38868, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.1474 - accuracy: 0.9627 - val_loss: 0.3887 - val_accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9668\n",
      "Epoch 8: val_loss did not improve from 0.38868\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.1412 - accuracy: 0.9668 - val_loss: 0.5877 - val_accuracy: 0.8039\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9732\n",
      "Epoch 9: val_loss did not improve from 0.38868\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.1301 - accuracy: 0.9732 - val_loss: 0.6081 - val_accuracy: 0.8235\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9687\n",
      "Epoch 10: val_loss did not improve from 0.38868\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.1267 - accuracy: 0.9687 - val_loss: 0.5024 - val_accuracy: 0.8235\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9631\n",
      "Epoch 1: val_loss improved from inf to 0.52577, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 41s 472ms/step - loss: 0.1397 - accuracy: 0.9631 - val_loss: 0.5258 - val_accuracy: 0.8431\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9597\n",
      "Epoch 2: val_loss improved from 0.52577 to 0.40533, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 40s 474ms/step - loss: 0.1375 - accuracy: 0.9597 - val_loss: 0.4053 - val_accuracy: 0.8235\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9635\n",
      "Epoch 3: val_loss did not improve from 0.40533\n",
      "84/84 [==============================] - 35s 412ms/step - loss: 0.1381 - accuracy: 0.9635 - val_loss: 0.6452 - val_accuracy: 0.7647\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9653\n",
      "Epoch 4: val_loss improved from 0.40533 to 0.40216, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 415ms/step - loss: 0.1321 - accuracy: 0.9653 - val_loss: 0.4022 - val_accuracy: 0.8039\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9705\n",
      "Epoch 5: val_loss did not improve from 0.40216\n",
      "84/84 [==============================] - 35s 415ms/step - loss: 0.1193 - accuracy: 0.9705 - val_loss: 0.4563 - val_accuracy: 0.8431\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9646\n",
      "Epoch 6: val_loss did not improve from 0.40216\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.1295 - accuracy: 0.9646 - val_loss: 0.4822 - val_accuracy: 0.7647\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9661\n",
      "Epoch 7: val_loss improved from 0.40216 to 0.38416, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 412ms/step - loss: 0.1209 - accuracy: 0.9661 - val_loss: 0.3842 - val_accuracy: 0.8039\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9728\n",
      "Epoch 8: val_loss did not improve from 0.38416\n",
      "84/84 [==============================] - 35s 411ms/step - loss: 0.1108 - accuracy: 0.9728 - val_loss: 0.4028 - val_accuracy: 0.9020\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9664\n",
      "Epoch 9: val_loss did not improve from 0.38416\n",
      "84/84 [==============================] - 35s 415ms/step - loss: 0.1239 - accuracy: 0.9664 - val_loss: 0.4289 - val_accuracy: 0.7647\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9687\n",
      "Epoch 10: val_loss did not improve from 0.38416\n",
      "84/84 [==============================] - 35s 412ms/step - loss: 0.1196 - accuracy: 0.9687 - val_loss: 0.5327 - val_accuracy: 0.7843\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9683\n",
      "Epoch 1: val_loss improved from inf to 0.29068, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 414ms/step - loss: 0.1167 - accuracy: 0.9683 - val_loss: 0.2907 - val_accuracy: 0.9216\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9672\n",
      "Epoch 2: val_loss did not improve from 0.29068\n",
      "84/84 [==============================] - 35s 412ms/step - loss: 0.1178 - accuracy: 0.9672 - val_loss: 0.4100 - val_accuracy: 0.8039\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9709\n",
      "Epoch 3: val_loss did not improve from 0.29068\n",
      "84/84 [==============================] - 35s 410ms/step - loss: 0.1125 - accuracy: 0.9709 - val_loss: 0.2943 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9761\n",
      "Epoch 4: val_loss did not improve from 0.29068\n",
      "84/84 [==============================] - 35s 410ms/step - loss: 0.0989 - accuracy: 0.9761 - val_loss: 1.4798 - val_accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9638\n",
      "Epoch 5: val_loss did not improve from 0.29068\n",
      "84/84 [==============================] - 35s 412ms/step - loss: 0.1231 - accuracy: 0.9638 - val_loss: 0.3783 - val_accuracy: 0.7647\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9709\n",
      "Epoch 6: val_loss did not improve from 0.29068\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.1095 - accuracy: 0.9709 - val_loss: 0.8319 - val_accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9705\n",
      "Epoch 7: val_loss did not improve from 0.29068\n",
      "84/84 [==============================] - 35s 414ms/step - loss: 0.1166 - accuracy: 0.9705 - val_loss: 0.3038 - val_accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9638\n",
      "Epoch 8: val_loss did not improve from 0.29068\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 0.1290 - accuracy: 0.9638 - val_loss: 0.9470 - val_accuracy: 0.6275\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9694\n",
      "Epoch 9: val_loss improved from 0.29068 to 0.25724, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 0.1207 - accuracy: 0.9694 - val_loss: 0.2572 - val_accuracy: 0.9216\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9724\n",
      "Epoch 10: val_loss did not improve from 0.25724\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.1055 - accuracy: 0.9724 - val_loss: 0.5155 - val_accuracy: 0.8235\n",
      "Learning rate for this round is: 0.0001\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9758\n",
      "Epoch 1: val_loss improved from inf to 0.33184, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 421ms/step - loss: 0.1024 - accuracy: 0.9758 - val_loss: 0.3318 - val_accuracy: 0.8824\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9743\n",
      "Epoch 2: val_loss improved from 0.33184 to 0.32027, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.1053 - accuracy: 0.9743 - val_loss: 0.3203 - val_accuracy: 0.8824\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9720\n",
      "Epoch 3: val_loss did not improve from 0.32027\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.1037 - accuracy: 0.9720 - val_loss: 0.3755 - val_accuracy: 0.8431\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9799\n",
      "Epoch 4: val_loss did not improve from 0.32027\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.0936 - accuracy: 0.9799 - val_loss: 0.4572 - val_accuracy: 0.8235\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9750\n",
      "Epoch 5: val_loss improved from 0.32027 to 0.23386, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.1086 - accuracy: 0.9750 - val_loss: 0.2339 - val_accuracy: 0.9216\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9746\n",
      "Epoch 6: val_loss improved from 0.23386 to 0.23302, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.0996 - accuracy: 0.9746 - val_loss: 0.2330 - val_accuracy: 0.9020\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9732\n",
      "Epoch 7: val_loss did not improve from 0.23302\n",
      "84/84 [==============================] - 44s 518ms/step - loss: 0.0977 - accuracy: 0.9732 - val_loss: 0.4125 - val_accuracy: 0.8039\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9735\n",
      "Epoch 8: val_loss did not improve from 0.23302\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.0998 - accuracy: 0.9735 - val_loss: 0.2383 - val_accuracy: 0.8824\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9746\n",
      "Epoch 9: val_loss did not improve from 0.23302\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.0953 - accuracy: 0.9746 - val_loss: 0.3183 - val_accuracy: 0.8431\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9754\n",
      "Epoch 10: val_loss did not improve from 0.23302\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 0.0968 - accuracy: 0.9754 - val_loss: 0.3560 - val_accuracy: 0.8627\n",
      "Learning rate for this round is: 0.0001\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9732\n",
      "Epoch 1: val_loss improved from inf to 0.34360, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.1025 - accuracy: 0.9732 - val_loss: 0.3436 - val_accuracy: 0.8235\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.9799\n",
      "Epoch 2: val_loss improved from 0.34360 to 0.22553, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.0884 - accuracy: 0.9799 - val_loss: 0.2255 - val_accuracy: 0.9216\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9787\n",
      "Epoch 3: val_loss did not improve from 0.22553\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.0852 - accuracy: 0.9787 - val_loss: 0.2826 - val_accuracy: 0.9020\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9773\n",
      "Epoch 4: val_loss did not improve from 0.22553\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.0882 - accuracy: 0.9773 - val_loss: 0.2461 - val_accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9814\n",
      "Epoch 5: val_loss did not improve from 0.22553\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 0.0838 - accuracy: 0.9814 - val_loss: 0.2366 - val_accuracy: 0.9216\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9795\n",
      "Epoch 6: val_loss did not improve from 0.22553\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 0.0859 - accuracy: 0.9795 - val_loss: 0.3148 - val_accuracy: 0.8235\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9743\n",
      "Epoch 7: val_loss did not improve from 0.22553\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.0882 - accuracy: 0.9743 - val_loss: 0.2267 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9791\n",
      "Epoch 8: val_loss did not improve from 0.22553\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 0.0888 - accuracy: 0.9791 - val_loss: 0.2874 - val_accuracy: 0.9020\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9784\n",
      "Epoch 9: val_loss did not improve from 0.22553\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.0860 - accuracy: 0.9784 - val_loss: 0.2359 - val_accuracy: 0.9020\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9773\n",
      "Epoch 10: val_loss did not improve from 0.22553\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 0.0864 - accuracy: 0.9773 - val_loss: 0.3179 - val_accuracy: 0.9020\n",
      "Updated accuracy after using 1 augmented training datasets: 90.2\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.9508\n",
      "Epoch 1: val_loss improved from inf to 0.58806, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 429ms/step - loss: 0.1724 - accuracy: 0.9508 - val_loss: 0.5881 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.9526\n",
      "Epoch 2: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 0.4213 - accuracy: 0.9526 - val_loss: 2.3613 - val_accuracy: 0.5882\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.9508\n",
      "Epoch 3: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.5156 - accuracy: 0.9508 - val_loss: 1.2320 - val_accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.9493\n",
      "Epoch 4: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.3739 - accuracy: 0.9493 - val_loss: 0.7500 - val_accuracy: 0.7647\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.9582\n",
      "Epoch 5: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.3838 - accuracy: 0.9582 - val_loss: 0.9508 - val_accuracy: 0.8039\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.9594\n",
      "Epoch 6: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 0.3228 - accuracy: 0.9594 - val_loss: 0.8055 - val_accuracy: 0.6275\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.9545\n",
      "Epoch 7: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 0.3244 - accuracy: 0.9545 - val_loss: 0.7010 - val_accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.9571\n",
      "Epoch 8: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.2586 - accuracy: 0.9571 - val_loss: 2.0161 - val_accuracy: 0.6275\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.9482\n",
      "Epoch 9: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.3186 - accuracy: 0.9482 - val_loss: 1.5786 - val_accuracy: 0.4118\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.9508\n",
      "Epoch 10: val_loss did not improve from 0.58806\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 0.3879 - accuracy: 0.9508 - val_loss: 3.1164 - val_accuracy: 0.5882\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.9579\n",
      "Epoch 1: val_loss improved from inf to 0.63146, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 446ms/step - loss: 0.2504 - accuracy: 0.9579 - val_loss: 0.6315 - val_accuracy: 0.7059\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9575\n",
      "Epoch 2: val_loss improved from 0.63146 to 0.62438, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 45s 534ms/step - loss: 0.2273 - accuracy: 0.9575 - val_loss: 0.6244 - val_accuracy: 0.6863\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9512\n",
      "Epoch 3: val_loss did not improve from 0.62438\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 0.2254 - accuracy: 0.9512 - val_loss: 0.7034 - val_accuracy: 0.6863\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9590\n",
      "Epoch 4: val_loss did not improve from 0.62438\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.2146 - accuracy: 0.9590 - val_loss: 0.7668 - val_accuracy: 0.8039\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9579\n",
      "Epoch 5: val_loss did not improve from 0.62438\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.2135 - accuracy: 0.9579 - val_loss: 0.6926 - val_accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9567\n",
      "Epoch 6: val_loss did not improve from 0.62438\n",
      "84/84 [==============================] - 35s 418ms/step - loss: 0.2159 - accuracy: 0.9567 - val_loss: 1.8076 - val_accuracy: 0.6275\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9523\n",
      "Epoch 7: val_loss improved from 0.62438 to 0.54009, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 0.2175 - accuracy: 0.9523 - val_loss: 0.5401 - val_accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9545\n",
      "Epoch 8: val_loss improved from 0.54009 to 0.52315, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.2112 - accuracy: 0.9545 - val_loss: 0.5231 - val_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9631\n",
      "Epoch 9: val_loss did not improve from 0.52315\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.1980 - accuracy: 0.9631 - val_loss: 0.9221 - val_accuracy: 0.6275\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9575\n",
      "Epoch 10: val_loss improved from 0.52315 to 0.51643, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.2049 - accuracy: 0.9575 - val_loss: 0.5164 - val_accuracy: 0.7843\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9579\n",
      "Epoch 1: val_loss improved from inf to 0.37650, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 430ms/step - loss: 0.1976 - accuracy: 0.9579 - val_loss: 0.3765 - val_accuracy: 0.8627\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.9605\n",
      "Epoch 2: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.1955 - accuracy: 0.9605 - val_loss: 0.7219 - val_accuracy: 0.5882\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9601\n",
      "Epoch 3: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 0.1782 - accuracy: 0.9601 - val_loss: 0.6011 - val_accuracy: 0.8235\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9635\n",
      "Epoch 4: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.1772 - accuracy: 0.9635 - val_loss: 0.7288 - val_accuracy: 0.7255\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.9571\n",
      "Epoch 5: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 0.2029 - accuracy: 0.9571 - val_loss: 1.4128 - val_accuracy: 0.5882\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9601\n",
      "Epoch 6: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 0.1983 - accuracy: 0.9601 - val_loss: 0.4334 - val_accuracy: 0.8431\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9549\n",
      "Epoch 7: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.2007 - accuracy: 0.9549 - val_loss: 0.6109 - val_accuracy: 0.7451\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9605\n",
      "Epoch 8: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.1860 - accuracy: 0.9605 - val_loss: 1.1829 - val_accuracy: 0.5098\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1855 - accuracy: 0.9575\n",
      "Epoch 9: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 0.1855 - accuracy: 0.9575 - val_loss: 0.9982 - val_accuracy: 0.6078\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9605\n",
      "Epoch 10: val_loss did not improve from 0.37650\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.2022 - accuracy: 0.9605 - val_loss: 0.3998 - val_accuracy: 0.9020\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.9571\n",
      "Epoch 1: val_loss improved from inf to 0.51238, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 0.1807 - accuracy: 0.9571 - val_loss: 0.5124 - val_accuracy: 0.8235\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9616\n",
      "Epoch 2: val_loss did not improve from 0.51238\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.1831 - accuracy: 0.9616 - val_loss: 0.6148 - val_accuracy: 0.7647\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.9500\n",
      "Epoch 3: val_loss improved from 0.51238 to 0.30259, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.2173 - accuracy: 0.9500 - val_loss: 0.3026 - val_accuracy: 0.9216\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9597\n",
      "Epoch 4: val_loss did not improve from 0.30259\n",
      "84/84 [==============================] - 37s 433ms/step - loss: 0.1933 - accuracy: 0.9597 - val_loss: 0.3775 - val_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.9631\n",
      "Epoch 5: val_loss did not improve from 0.30259\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.1834 - accuracy: 0.9631 - val_loss: 0.5403 - val_accuracy: 0.8039\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.9668\n",
      "Epoch 6: val_loss did not improve from 0.30259\n",
      "84/84 [==============================] - 41s 488ms/step - loss: 0.1788 - accuracy: 0.9668 - val_loss: 1.3073 - val_accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9579\n",
      "Epoch 7: val_loss did not improve from 0.30259\n",
      "84/84 [==============================] - 40s 472ms/step - loss: 0.1942 - accuracy: 0.9579 - val_loss: 0.6594 - val_accuracy: 0.7255\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.9567\n",
      "Epoch 8: val_loss improved from 0.30259 to 0.28759, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 433ms/step - loss: 0.2023 - accuracy: 0.9567 - val_loss: 0.2876 - val_accuracy: 0.9216\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9601\n",
      "Epoch 9: val_loss did not improve from 0.28759\n",
      "84/84 [==============================] - 810s 468ms/step - loss: 0.1888 - accuracy: 0.9601 - val_loss: 0.5510 - val_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.9616\n",
      "Epoch 10: val_loss did not improve from 0.28759\n",
      "84/84 [==============================] - 44s 525ms/step - loss: 0.1852 - accuracy: 0.9616 - val_loss: 0.3565 - val_accuracy: 0.9216\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9586\n",
      "Epoch 1: val_loss improved from inf to 0.41867, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 0.1802 - accuracy: 0.9586 - val_loss: 0.4187 - val_accuracy: 0.8235\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9635\n",
      "Epoch 2: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.1691 - accuracy: 0.9635 - val_loss: 0.8403 - val_accuracy: 0.5882\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9571\n",
      "Epoch 3: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 0.1845 - accuracy: 0.9571 - val_loss: 0.6391 - val_accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9653\n",
      "Epoch 4: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 38s 450ms/step - loss: 0.1777 - accuracy: 0.9653 - val_loss: 1.2865 - val_accuracy: 0.7451\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9567\n",
      "Epoch 5: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 0.1956 - accuracy: 0.9567 - val_loss: 0.5199 - val_accuracy: 0.7451\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9713\n",
      "Epoch 6: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 0.1634 - accuracy: 0.9713 - val_loss: 0.4482 - val_accuracy: 0.8039\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9597\n",
      "Epoch 7: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.1831 - accuracy: 0.9597 - val_loss: 0.4584 - val_accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9586\n",
      "Epoch 8: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.1962 - accuracy: 0.9586 - val_loss: 2.0161 - val_accuracy: 0.4706\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9616\n",
      "Epoch 9: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.1977 - accuracy: 0.9616 - val_loss: 0.6971 - val_accuracy: 0.5882\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.9623\n",
      "Epoch 10: val_loss did not improve from 0.41867\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.1832 - accuracy: 0.9623 - val_loss: 0.6989 - val_accuracy: 0.6667\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9691\n",
      "Epoch 1: val_loss improved from inf to 0.56792, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 433ms/step - loss: 0.1576 - accuracy: 0.9691 - val_loss: 0.5679 - val_accuracy: 0.8039\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9795\n",
      "Epoch 2: val_loss improved from 0.56792 to 0.32874, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.1215 - accuracy: 0.9795 - val_loss: 0.3287 - val_accuracy: 0.9020\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9717\n",
      "Epoch 3: val_loss improved from 0.32874 to 0.28930, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 0.1280 - accuracy: 0.9717 - val_loss: 0.2893 - val_accuracy: 0.9216\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9709\n",
      "Epoch 4: val_loss improved from 0.28930 to 0.25948, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.1304 - accuracy: 0.9709 - val_loss: 0.2595 - val_accuracy: 0.9412\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9705\n",
      "Epoch 5: val_loss did not improve from 0.25948\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 0.1211 - accuracy: 0.9705 - val_loss: 0.6923 - val_accuracy: 0.7451\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9746\n",
      "Epoch 6: val_loss did not improve from 0.25948\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.1088 - accuracy: 0.9746 - val_loss: 0.5079 - val_accuracy: 0.7843\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9773\n",
      "Epoch 7: val_loss did not improve from 0.25948\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.1081 - accuracy: 0.9773 - val_loss: 0.9700 - val_accuracy: 0.7059\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9709\n",
      "Epoch 8: val_loss did not improve from 0.25948\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.1142 - accuracy: 0.9709 - val_loss: 0.2888 - val_accuracy: 0.9020\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9776\n",
      "Epoch 9: val_loss improved from 0.25948 to 0.20578, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.1031 - accuracy: 0.9776 - val_loss: 0.2058 - val_accuracy: 0.9608\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9780\n",
      "Epoch 10: val_loss improved from 0.20578 to 0.18671, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.0966 - accuracy: 0.9780 - val_loss: 0.1867 - val_accuracy: 0.9412\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9780\n",
      "Epoch 1: val_loss improved from inf to 0.25284, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 430ms/step - loss: 0.1003 - accuracy: 0.9780 - val_loss: 0.2528 - val_accuracy: 0.8824\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9787 \n",
      "Epoch 2: val_loss did not improve from 0.25284\n",
      "84/84 [==============================] - 938s 11s/step - loss: 0.0916 - accuracy: 0.9787 - val_loss: 0.3209 - val_accuracy: 0.8235\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9739\n",
      "Epoch 3: val_loss improved from 0.25284 to 0.19912, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 281s 3s/step - loss: 0.0939 - accuracy: 0.9739 - val_loss: 0.1991 - val_accuracy: 0.9412\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9802\n",
      "Epoch 4: val_loss did not improve from 0.19912\n",
      "84/84 [==============================] - 37s 433ms/step - loss: 0.0897 - accuracy: 0.9802 - val_loss: 0.2803 - val_accuracy: 0.8431\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9769\n",
      "Epoch 5: val_loss did not improve from 0.19912\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.0911 - accuracy: 0.9769 - val_loss: 0.2314 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9802\n",
      "Epoch 6: val_loss improved from 0.19912 to 0.18846, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 0.0900 - accuracy: 0.9802 - val_loss: 0.1885 - val_accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9806\n",
      "Epoch 7: val_loss did not improve from 0.18846\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.0818 - accuracy: 0.9806 - val_loss: 0.4826 - val_accuracy: 0.7451\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9780\n",
      "Epoch 8: val_loss improved from 0.18846 to 0.17677, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 0.0879 - accuracy: 0.9780 - val_loss: 0.1768 - val_accuracy: 0.9608\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9773\n",
      "Epoch 9: val_loss improved from 0.17677 to 0.16966, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 0.0953 - accuracy: 0.9773 - val_loss: 0.1697 - val_accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9765\n",
      "Epoch 10: val_loss did not improve from 0.16966\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 0.0924 - accuracy: 0.9765 - val_loss: 0.2117 - val_accuracy: 0.9412\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9743\n",
      "Epoch 1: val_loss improved from inf to 0.21728, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 438ms/step - loss: 0.0933 - accuracy: 0.9743 - val_loss: 0.2173 - val_accuracy: 0.9412\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9806\n",
      "Epoch 2: val_loss did not improve from 0.21728\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 0.0845 - accuracy: 0.9806 - val_loss: 0.2213 - val_accuracy: 0.9216\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9799\n",
      "Epoch 3: val_loss improved from 0.21728 to 0.18310, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 0.0860 - accuracy: 0.9799 - val_loss: 0.1831 - val_accuracy: 0.9412\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9787\n",
      "Epoch 4: val_loss did not improve from 0.18310\n",
      "84/84 [==============================] - 38s 446ms/step - loss: 0.0856 - accuracy: 0.9787 - val_loss: 0.2223 - val_accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9787\n",
      "Epoch 5: val_loss did not improve from 0.18310\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.0897 - accuracy: 0.9787 - val_loss: 0.1961 - val_accuracy: 0.9412\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9787\n",
      "Epoch 6: val_loss did not improve from 0.18310\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 0.0827 - accuracy: 0.9787 - val_loss: 0.9173 - val_accuracy: 0.6863\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9780\n",
      "Epoch 7: val_loss did not improve from 0.18310\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.0833 - accuracy: 0.9780 - val_loss: 0.3096 - val_accuracy: 0.8824\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9799\n",
      "Epoch 8: val_loss did not improve from 0.18310\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.0845 - accuracy: 0.9799 - val_loss: 0.3636 - val_accuracy: 0.8431\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9791\n",
      "Epoch 9: val_loss did not improve from 0.18310\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.0821 - accuracy: 0.9791 - val_loss: 0.2444 - val_accuracy: 0.9216\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9814\n",
      "Epoch 10: val_loss did not improve from 0.18310\n",
      "84/84 [==============================] - 43s 507ms/step - loss: 0.0787 - accuracy: 0.9814 - val_loss: 0.2081 - val_accuracy: 0.9216\n",
      "Learning rate for this round is: 0.0001\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9810\n",
      "Epoch 1: val_loss improved from inf to 0.21793, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 43s 499ms/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.2179 - val_accuracy: 0.8627\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9784\n",
      "Epoch 2: val_loss improved from 0.21793 to 0.19052, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 446ms/step - loss: 0.0812 - accuracy: 0.9784 - val_loss: 0.1905 - val_accuracy: 0.9216\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9795\n",
      "Epoch 3: val_loss did not improve from 0.19052\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 0.0780 - accuracy: 0.9795 - val_loss: 0.2765 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9836\n",
      "Epoch 4: val_loss improved from 0.19052 to 0.17531, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 0.0748 - accuracy: 0.9836 - val_loss: 0.1753 - val_accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9870\n",
      "Epoch 5: val_loss improved from 0.17531 to 0.15647, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 0.0640 - accuracy: 0.9870 - val_loss: 0.1565 - val_accuracy: 0.9608\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9866\n",
      "Epoch 6: val_loss did not improve from 0.15647\n",
      "84/84 [==============================] - 38s 449ms/step - loss: 0.0703 - accuracy: 0.9866 - val_loss: 0.1614 - val_accuracy: 0.9608\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9817\n",
      "Epoch 7: val_loss did not improve from 0.15647\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 0.0652 - accuracy: 0.9817 - val_loss: 0.1590 - val_accuracy: 0.9608\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9825\n",
      "Epoch 8: val_loss improved from 0.15647 to 0.15215, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 0.0711 - accuracy: 0.9825 - val_loss: 0.1521 - val_accuracy: 0.9608\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9855\n",
      "Epoch 9: val_loss improved from 0.15215 to 0.15130, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 452ms/step - loss: 0.0665 - accuracy: 0.9855 - val_loss: 0.1513 - val_accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9832\n",
      "Epoch 10: val_loss did not improve from 0.15130\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.0722 - accuracy: 0.9832 - val_loss: 0.1601 - val_accuracy: 0.9608\n",
      "Updated accuracy after using 2 augmented training datasets: 96.08\n"
     ]
    }
   ],
   "source": [
    "training_history: Dict[str, List[float]] = {}\n",
    "for his_key in ('loss', 'accuracy', 'val_loss', 'val_accuracy'):\n",
    "    training_history[his_key] = [] \n",
    "\n",
    "acc_per_100_epochs: List[float] = []\n",
    "\n",
    "# first 50% epochs: 2e-3, 50%-80% epochs: 5e-4, 80%-100% epochs: 1e-4\n",
    "def obtain_lr(initial_lr: float, total_epochs: int, round_index: int, epochs_per_round: int) -> float:\n",
    "    assert total_epochs>=10 and total_epochs%10==0, \"The number of datasets must be divsible by 10!\"\n",
    "    assert 0<(round_index*epochs_per_round)<=total_epochs\n",
    "    return initial_lr if round_index*epochs_per_round<=total_epochs/2 else initial_lr/4 if round_index*epochs_per_round<=total_epochs*0.8 else initial_lr/20\n",
    "\n",
    "# 100 epochs for each augmented dataset, maximally 500 epochs, stop training when the average validation accuracy of last 10 epochs becomes above 0.9\n",
    "stop_training: bool = False\n",
    "rounds_per_dataset: int = 10\n",
    "for dataset_count in range(1, 6):\n",
    "    if stop_training: break\n",
    "    for round_count in range(1, rounds_per_dataset+1):\n",
    "        lr = obtain_lr(2e-3, 100, round_count, 10)\n",
    "        print(f'Learning rate for this round is: {str(lr)}')\n",
    "        model, history = fitted_model(model, lr, train_iterator, test_iterator)\n",
    "        for his_key in history.history.keys():\n",
    "            training_history[his_key].extend(history.history[his_key])\n",
    "        sliding_avg_10_acc: float = mean(training_history['val_accuracy'][-10:])\n",
    "        if sliding_avg_10_acc > 0.9: \n",
    "            stop_training = True   \n",
    "            break\n",
    "    acc = model.evaluate(test_iterator, verbose=0)[1]\n",
    "    print(f\"Updated accuracy after using {str(dataset_count)} augmented training datasets: {round(acc, 4)*100}\")\n",
    "    model.save(\"pneumonia_aug_CNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639095a",
   "metadata": {},
   "source": [
    "#### We are able to obtain an accuracy at 96.08% using the built in layers (after 200 epochs of training), which is pretty high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13123999",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c014f",
   "metadata": {},
   "source": [
    "### Step 3. Write our own convolutional, MaxPooling, and Dense layers using <code>keras.backend.*</code> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a74521d",
   "metadata": {},
   "source": [
    "Two of our self-written layers (<code>MyConv2D</code> and <code>DenseLayer</code>) are child classes of <b>tf.keras.layers.Layer</b> (<code>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer</code>)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f1de17c",
   "metadata": {},
   "source": [
    "Convolutional Layer (to be updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "74e2f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv2D(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, kernel_initializer: tf.keras.initializers.Initializer, filters: int, kernel_size: Tuple[int] = (3, 3), activation:str='relu', **kwargs):\n",
    "        # assertions for input params\n",
    "        assert isinstance(filters, int) and filters > 0\n",
    "        assert isinstance(kernel_size, tuple) and isinstance(kernel_initializer, tf.keras.initializers.Initializer) \n",
    "        assert len(kernel_size)==2 and kernel_size[0]>1 and kernel_size[1]>1\n",
    "        assert isinstance(activation, str) and activation in {\"relu\", \"sigmoid\"}\n",
    "        # class attribute assignment\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.activation = activation\n",
    "        # call the constructor of the parent class of MyConv (tf.keras.layers.Layer)\n",
    "        super(MyConv2D, self).__init__(**kwargs)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'kernel_initializer': self.kernel_initializer,\n",
    "            'activation': self.activation\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # assertions for input params\n",
    "        assert len(input_shape) == 4\n",
    "        # update the kernels of the 2D convolutional layer\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                       shape= self.kernel_size + (input_shape[-1], self.filters),\n",
    "                                       initializer = self.kernel_initializer,\n",
    "                                       trainable=True)\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(name='bias',\n",
    "                             initial_value=b_init(shape=(input_shape[1] - self.kernel_size[0] + 1, input_shape[2] - self.kernel_size[1] + 1) + (self.filters, )),\n",
    "                             trainable=True)\n",
    "        # call the .build() method of the parent class \"Layer\"\n",
    "        super(MyConv2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = K.conv2d(inputs, self.kernel, data_format=\"channels_last\")\n",
    "        return tf.nn.relu(output + self.b) if self.activation==\"relu\" else tf.nn.sigmoid(output + self.b)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[1] - self.kernel_size[0] + 1, input_shape[2] - self.kernel_size[1] + 1) + (self.filters, )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd70521",
   "metadata": {},
   "source": [
    "Max Pooling layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eec1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool2d(inputs):\n",
    "    max_x =  K.pool2d(inputs, pool_size=(2, 2), strides=(2, 2))\n",
    "    return max_x\n",
    "\n",
    "def max_pool2d_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        shape[2] /= 2\n",
    "        shape[3] /= 2\n",
    "    else:\n",
    "        shape[1] /= 2\n",
    "        shape[2] /= 2\n",
    "    return tuple(shape)\n",
    "\n",
    "def MyMaxPool2D() -> Lambda:\n",
    "    return Lambda(function=max_pool2d, output_shape=max_pool2d_output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d024b",
   "metadata": {},
   "source": [
    "Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d3b14e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_regularizer: tf.keras.regularizers.Regularizer=None, units:int=1, activation:str='relu', **kwargs):\n",
    "        # assertions for input params\n",
    "        assert isinstance(units, int) and units > 0\n",
    "        assert isinstance(activation, str) and activation in {\"relu\", \"sigmoid\"}\n",
    "        # class attribute assignment \n",
    "        self.units = units\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.activation = activation\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'units': self.units,\n",
    "            'kernel_regularizer': self.kernel_regularizer,\n",
    "            'activation': self.activation\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # assertions for input params\n",
    "        assert len(input_shape) > 1\n",
    "        # class attribute assignment \n",
    "        input_shape = tuple(input_shape)\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = self.add_weight(name='kernel',  \n",
    "                        shape=(input_shape[-1], self.units),\n",
    "                        initializer='uniform',\n",
    "                        regularizer=self.kernel_regularizer,\n",
    "                        trainable=True)\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(name='bias',\n",
    "                             initial_value=b_init(shape=(self.units, )),\n",
    "                             trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b) if self.activation==\"relu\" else tf.nn.sigmoid(tf.matmul(inputs, self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "198b8987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_conv2d_27 (MyConv2D)     (32, 222, 222, 32)        1577952   \n",
      "                                                                 \n",
      " batch_normalization_82 (Bat  (32, 222, 222, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lambda_81 (Lambda)          (32, 111, 111, 32)        0         \n",
      "                                                                 \n",
      " my_conv2d_28 (MyConv2D)     (32, 109, 109, 64)        778816    \n",
      "                                                                 \n",
      " batch_normalization_83 (Bat  (32, 109, 109, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lambda_82 (Lambda)          (32, 54, 54, 64)          0         \n",
      "                                                                 \n",
      " my_conv2d_29 (MyConv2D)     (32, 52, 52, 128)         419840    \n",
      "                                                                 \n",
      " batch_normalization_84 (Bat  (32, 52, 52, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lambda_83 (Lambda)          (32, 26, 26, 128)         0         \n",
      "                                                                 \n",
      " my_conv2d_30 (MyConv2D)     (32, 24, 24, 256)         442368    \n",
      "                                                                 \n",
      " batch_normalization_85 (Bat  (32, 24, 24, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lambda_84 (Lambda)          (32, 12, 12, 256)         0         \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (32, 36864)               0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (32, 36864)               0         \n",
      "                                                                 \n",
      " my_dense_38 (MyDense)       (32, 512)                 18874880  \n",
      "                                                                 \n",
      " my_dense_39 (MyDense)       (32, 1)                   513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,096,289\n",
      "Trainable params: 22,095,329\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_self_CNN_Model(Image_size: tuple, Image_channels=3) -> tf.keras.Sequential:\n",
    "    assert len(Image_Size)==2 and Image_Size[0]>0 and Image_Size[1]>0, \"Image_size must be a tuple of two positive integers!\"\n",
    "    model=Sequential()\n",
    "    model.add(MyConv2D(filters=32, activation='relu', kernel_initializer=keras.initializers.he_uniform(seed=42)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MyMaxPool2D())\n",
    "    model.add(MyConv2D(filters=64, kernel_initializer=keras.initializers.he_uniform(seed=42), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MyMaxPool2D())\n",
    "    model.add(MyConv2D(filters=128, kernel_initializer=keras.initializers.he_uniform(seed=42), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MyMaxPool2D())\n",
    "    model.add(MyConv2D(filters=256, kernel_initializer=keras.initializers.he_uniform(seed=42), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MyMaxPool2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MyDense(units=512, kernel_regularizer=keras.regularizers.L2(5e-3)))\n",
    "    model.add(MyDense(units=1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "own_model = create_self_CNN_Model(Image_size=Image_Size)\n",
    "own_model.build((Batch_Size, Image_Width, Image_Height, Image_Channels))\n",
    "own_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4317f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitted_own_model(model: Sequential, lr: float, train_imgs: keras.preprocessing.image.DirectoryIterator, val_imgs: keras.preprocessing.image.NumpyArrayIterator) -> Tuple:\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='weights.best.inc.blond.hdf5', verbose=1, save_best_only=True)\n",
    "    model_history = model.fit(train_imgs, validation_data=val_imgs, steps_per_epoch=len(train_imgs), validation_steps=len(val_imgs), epochs=10, callbacks=[checkpointer])\n",
    "    return (model, model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "be240972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 32.2612 - accuracy: 0.8113\n",
      "Epoch 1: val_loss improved from inf to 15.45371, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 47s 556ms/step - loss: 32.2612 - accuracy: 0.8113 - val_loss: 15.4537 - val_accuracy: 0.4118\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 3.7399 - accuracy: 0.8576\n",
      "Epoch 2: val_loss improved from 15.45371 to 15.26706, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 3.7399 - accuracy: 0.8576 - val_loss: 15.2671 - val_accuracy: 0.4118\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 2.0319 - accuracy: 0.8512\n",
      "Epoch 3: val_loss improved from 15.26706 to 14.33803, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 2.0319 - accuracy: 0.8512 - val_loss: 14.3380 - val_accuracy: 0.4118\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.6311 - accuracy: 0.8658\n",
      "Epoch 4: val_loss improved from 14.33803 to 10.16239, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 1.6311 - accuracy: 0.8658 - val_loss: 10.1624 - val_accuracy: 0.4118\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.3611 - accuracy: 0.8702\n",
      "Epoch 5: val_loss did not improve from 10.16239\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 1.3611 - accuracy: 0.8702 - val_loss: 14.3303 - val_accuracy: 0.4118\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.1484 - accuracy: 0.8732\n",
      "Epoch 6: val_loss improved from 10.16239 to 2.82441, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 1.1484 - accuracy: 0.8732 - val_loss: 2.8244 - val_accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.2643 - accuracy: 0.8826\n",
      "Epoch 7: val_loss improved from 2.82441 to 2.38578, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 1.2643 - accuracy: 0.8826 - val_loss: 2.3858 - val_accuracy: 0.5686\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.2014 - accuracy: 0.8818\n",
      "Epoch 8: val_loss improved from 2.38578 to 1.40602, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 1.2014 - accuracy: 0.8818 - val_loss: 1.4060 - val_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.8870\n",
      "Epoch 9: val_loss improved from 1.40602 to 1.22217, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 1.0044 - accuracy: 0.8870 - val_loss: 1.2222 - val_accuracy: 0.7647\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.9102 - accuracy: 0.8982\n",
      "Epoch 10: val_loss improved from 1.22217 to 1.17029, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.9102 - accuracy: 0.8982 - val_loss: 1.1703 - val_accuracy: 0.7059\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.4656 - accuracy: 0.8710\n",
      "Epoch 1: val_loss improved from inf to 2.59817, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 419ms/step - loss: 1.4656 - accuracy: 0.8710 - val_loss: 2.5982 - val_accuracy: 0.6078\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.7979 - accuracy: 0.8751\n",
      "Epoch 2: val_loss improved from 2.59817 to 2.04824, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 1.7979 - accuracy: 0.8751 - val_loss: 2.0482 - val_accuracy: 0.6078\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.4569 - accuracy: 0.8818\n",
      "Epoch 3: val_loss improved from 2.04824 to 1.31565, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 1.4569 - accuracy: 0.8818 - val_loss: 1.3157 - val_accuracy: 0.6863\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.9316 - accuracy: 0.8937\n",
      "Epoch 4: val_loss did not improve from 1.31565\n",
      "84/84 [==============================] - 43s 515ms/step - loss: 0.9316 - accuracy: 0.8937 - val_loss: 1.9223 - val_accuracy: 0.6275\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.0652 - accuracy: 0.8885\n",
      "Epoch 5: val_loss did not improve from 1.31565\n",
      "84/84 [==============================] - 38s 452ms/step - loss: 1.0652 - accuracy: 0.8885 - val_loss: 1.6033 - val_accuracy: 0.6275\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.1508 - accuracy: 0.8956\n",
      "Epoch 6: val_loss did not improve from 1.31565\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 1.1508 - accuracy: 0.8956 - val_loss: 1.5608 - val_accuracy: 0.6275\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 1.0874 - accuracy: 0.8893\n",
      "Epoch 7: val_loss did not improve from 1.31565\n",
      "84/84 [==============================] - 35s 413ms/step - loss: 1.0874 - accuracy: 0.8893 - val_loss: 1.4668 - val_accuracy: 0.6863\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.9599 - accuracy: 0.9053\n",
      "Epoch 8: val_loss improved from 1.31565 to 1.24959, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 413ms/step - loss: 0.9599 - accuracy: 0.9053 - val_loss: 1.2496 - val_accuracy: 0.6078\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7917 - accuracy: 0.9045\n",
      "Epoch 9: val_loss improved from 1.24959 to 1.02015, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 414ms/step - loss: 0.7917 - accuracy: 0.9045 - val_loss: 1.0202 - val_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.8993\n",
      "Epoch 10: val_loss did not improve from 1.02015\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.6439 - accuracy: 0.8993 - val_loss: 1.0935 - val_accuracy: 0.6078\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.9101\n",
      "Epoch 1: val_loss improved from inf to 1.12489, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 0.6077 - accuracy: 0.9101 - val_loss: 1.1249 - val_accuracy: 0.7843\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7867 - accuracy: 0.9157\n",
      "Epoch 2: val_loss improved from 1.12489 to 0.92483, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.7867 - accuracy: 0.9157 - val_loss: 0.9248 - val_accuracy: 0.8235\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7523 - accuracy: 0.9083\n",
      "Epoch 3: val_loss did not improve from 0.92483\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.7523 - accuracy: 0.9083 - val_loss: 1.3345 - val_accuracy: 0.4314\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.9198\n",
      "Epoch 4: val_loss did not improve from 0.92483\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.6875 - accuracy: 0.9198 - val_loss: 1.6939 - val_accuracy: 0.5882\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.9124\n",
      "Epoch 5: val_loss did not improve from 0.92483\n",
      "84/84 [==============================] - 35s 414ms/step - loss: 0.5723 - accuracy: 0.9124 - val_loss: 1.9025 - val_accuracy: 0.5882\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 0.9109\n",
      "Epoch 6: val_loss improved from 0.92483 to 0.57118, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 415ms/step - loss: 0.5436 - accuracy: 0.9109 - val_loss: 0.5712 - val_accuracy: 0.8627\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.9169\n",
      "Epoch 7: val_loss did not improve from 0.57118\n",
      "84/84 [==============================] - 35s 415ms/step - loss: 0.4448 - accuracy: 0.9169 - val_loss: 0.7545 - val_accuracy: 0.7255\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.9239\n",
      "Epoch 8: val_loss did not improve from 0.57118\n",
      "84/84 [==============================] - 35s 414ms/step - loss: 0.4452 - accuracy: 0.9239 - val_loss: 0.9589 - val_accuracy: 0.6471\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.9336\n",
      "Epoch 9: val_loss did not improve from 0.57118\n",
      "84/84 [==============================] - 35s 414ms/step - loss: 0.3635 - accuracy: 0.9336 - val_loss: 1.0311 - val_accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.9161\n",
      "Epoch 10: val_loss did not improve from 0.57118\n",
      "84/84 [==============================] - 35s 418ms/step - loss: 0.3286 - accuracy: 0.9161 - val_loss: 1.1263 - val_accuracy: 0.4902\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.9325\n",
      "Epoch 1: val_loss improved from inf to 0.93862, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 418ms/step - loss: 0.3319 - accuracy: 0.9325 - val_loss: 0.9386 - val_accuracy: 0.5686\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.9280\n",
      "Epoch 2: val_loss improved from 0.93862 to 0.82251, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 417ms/step - loss: 0.3585 - accuracy: 0.9280 - val_loss: 0.8225 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.9265\n",
      "Epoch 3: val_loss improved from 0.82251 to 0.59711, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 0.3634 - accuracy: 0.9265 - val_loss: 0.5971 - val_accuracy: 0.7647\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3119 - accuracy: 0.9396\n",
      "Epoch 4: val_loss improved from 0.59711 to 0.58720, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 0.3119 - accuracy: 0.9396 - val_loss: 0.5872 - val_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.9284\n",
      "Epoch 5: val_loss did not improve from 0.58720\n",
      "84/84 [==============================] - 35s 412ms/step - loss: 0.3149 - accuracy: 0.9284 - val_loss: 0.6036 - val_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.9303\n",
      "Epoch 6: val_loss did not improve from 0.58720\n",
      "84/84 [==============================] - 35s 415ms/step - loss: 0.3085 - accuracy: 0.9303 - val_loss: 0.7187 - val_accuracy: 0.6863\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.9374\n",
      "Epoch 7: val_loss did not improve from 0.58720\n",
      "84/84 [==============================] - 182s 2s/step - loss: 0.2762 - accuracy: 0.9374 - val_loss: 1.3340 - val_accuracy: 0.5882\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.9403 \n",
      "Epoch 8: val_loss did not improve from 0.58720\n",
      "84/84 [==============================] - 2632s 32s/step - loss: 0.2661 - accuracy: 0.9403 - val_loss: 0.7210 - val_accuracy: 0.6863\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.9389\n",
      "Epoch 9: val_loss did not improve from 0.58720\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.2639 - accuracy: 0.9389 - val_loss: 0.9616 - val_accuracy: 0.5882\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.9351\n",
      "Epoch 10: val_loss improved from 0.58720 to 0.52040, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.2674 - accuracy: 0.9351 - val_loss: 0.5204 - val_accuracy: 0.8431\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9351\n",
      "Epoch 1: val_loss improved from inf to 1.38625, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 41s 446ms/step - loss: 0.2720 - accuracy: 0.9351 - val_loss: 1.3863 - val_accuracy: 0.5098\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2422 - accuracy: 0.9396\n",
      "Epoch 2: val_loss improved from 1.38625 to 0.61388, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 0.2422 - accuracy: 0.9396 - val_loss: 0.6139 - val_accuracy: 0.7843\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.9433\n",
      "Epoch 3: val_loss did not improve from 0.61388\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 0.2568 - accuracy: 0.9433 - val_loss: 0.8813 - val_accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.9422\n",
      "Epoch 4: val_loss did not improve from 0.61388\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.2526 - accuracy: 0.9422 - val_loss: 1.3844 - val_accuracy: 0.4314\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.9430\n",
      "Epoch 5: val_loss improved from 0.61388 to 0.59390, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.2475 - accuracy: 0.9430 - val_loss: 0.5939 - val_accuracy: 0.8039\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.9400\n",
      "Epoch 6: val_loss did not improve from 0.59390\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.2495 - accuracy: 0.9400 - val_loss: 1.0804 - val_accuracy: 0.6275\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.9452\n",
      "Epoch 7: val_loss improved from 0.59390 to 0.41213, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.2389 - accuracy: 0.9452 - val_loss: 0.4121 - val_accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9459\n",
      "Epoch 8: val_loss did not improve from 0.41213\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.2383 - accuracy: 0.9459 - val_loss: 0.5812 - val_accuracy: 0.7255\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9500\n",
      "Epoch 9: val_loss did not improve from 0.41213\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 0.2335 - accuracy: 0.9500 - val_loss: 0.5772 - val_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9497\n",
      "Epoch 10: val_loss did not improve from 0.41213\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.2324 - accuracy: 0.9497 - val_loss: 0.5187 - val_accuracy: 0.8235\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.9512\n",
      "Epoch 1: val_loss improved from inf to 0.44860, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 431ms/step - loss: 0.2041 - accuracy: 0.9512 - val_loss: 0.4486 - val_accuracy: 0.8431\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9560\n",
      "Epoch 2: val_loss did not improve from 0.44860\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.1777 - accuracy: 0.9560 - val_loss: 0.8714 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9575\n",
      "Epoch 3: val_loss did not improve from 0.44860\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 0.1651 - accuracy: 0.9575 - val_loss: 0.5793 - val_accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9612\n",
      "Epoch 4: val_loss did not improve from 0.44860\n",
      "84/84 [==============================] - 44s 521ms/step - loss: 0.1572 - accuracy: 0.9612 - val_loss: 0.4602 - val_accuracy: 0.8039\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9594\n",
      "Epoch 5: val_loss improved from 0.44860 to 0.38295, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 42s 497ms/step - loss: 0.1599 - accuracy: 0.9594 - val_loss: 0.3830 - val_accuracy: 0.8431\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9564\n",
      "Epoch 6: val_loss did not improve from 0.38295\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.1537 - accuracy: 0.9564 - val_loss: 0.5353 - val_accuracy: 0.7451\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9642\n",
      "Epoch 7: val_loss did not improve from 0.38295\n",
      "84/84 [==============================] - 37s 433ms/step - loss: 0.1475 - accuracy: 0.9642 - val_loss: 0.3902 - val_accuracy: 0.8235\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9620\n",
      "Epoch 8: val_loss did not improve from 0.38295\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.1421 - accuracy: 0.9620 - val_loss: 0.4182 - val_accuracy: 0.8039\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9657\n",
      "Epoch 9: val_loss did not improve from 0.38295\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 0.1395 - accuracy: 0.9657 - val_loss: 0.7159 - val_accuracy: 0.6863\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9627\n",
      "Epoch 10: val_loss did not improve from 0.38295\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.1393 - accuracy: 0.9627 - val_loss: 0.4570 - val_accuracy: 0.7451\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.9657\n",
      "Epoch 1: val_loss improved from inf to 0.38937, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 433ms/step - loss: 0.1282 - accuracy: 0.9657 - val_loss: 0.3894 - val_accuracy: 0.8431\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9601\n",
      "Epoch 2: val_loss did not improve from 0.38937\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 0.1406 - accuracy: 0.9601 - val_loss: 0.4645 - val_accuracy: 0.7647\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9653\n",
      "Epoch 3: val_loss did not improve from 0.38937\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.1342 - accuracy: 0.9653 - val_loss: 0.4620 - val_accuracy: 0.8039\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9664\n",
      "Epoch 4: val_loss improved from 0.38937 to 0.32712, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 0.1300 - accuracy: 0.9664 - val_loss: 0.3271 - val_accuracy: 0.9412\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9638\n",
      "Epoch 5: val_loss did not improve from 0.32712\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 0.1371 - accuracy: 0.9638 - val_loss: 0.3311 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9661\n",
      "Epoch 6: val_loss did not improve from 0.32712\n",
      "84/84 [==============================] - 38s 450ms/step - loss: 0.1345 - accuracy: 0.9661 - val_loss: 0.6432 - val_accuracy: 0.8235\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9661\n",
      "Epoch 7: val_loss did not improve from 0.32712\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 0.1230 - accuracy: 0.9661 - val_loss: 0.6072 - val_accuracy: 0.7059\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9635\n",
      "Epoch 8: val_loss did not improve from 0.32712\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 0.1311 - accuracy: 0.9635 - val_loss: 0.4501 - val_accuracy: 0.8235\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9705\n",
      "Epoch 9: val_loss did not improve from 0.32712\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.1207 - accuracy: 0.9705 - val_loss: 0.5295 - val_accuracy: 0.7255\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9676\n",
      "Epoch 10: val_loss did not improve from 0.32712\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 0.1251 - accuracy: 0.9676 - val_loss: 0.3743 - val_accuracy: 0.8431\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9638\n",
      "Epoch 1: val_loss improved from inf to 0.49783, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 440ms/step - loss: 0.1281 - accuracy: 0.9638 - val_loss: 0.4978 - val_accuracy: 0.7843\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9672\n",
      "Epoch 2: val_loss improved from 0.49783 to 0.33382, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 0.1199 - accuracy: 0.9672 - val_loss: 0.3338 - val_accuracy: 0.9020\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9653\n",
      "Epoch 3: val_loss did not improve from 0.33382\n",
      "84/84 [==============================] - 38s 446ms/step - loss: 0.1288 - accuracy: 0.9653 - val_loss: 0.3598 - val_accuracy: 0.8627\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9668\n",
      "Epoch 4: val_loss did not improve from 0.33382\n",
      "84/84 [==============================] - 38s 446ms/step - loss: 0.1250 - accuracy: 0.9668 - val_loss: 0.4067 - val_accuracy: 0.7647\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9705\n",
      "Epoch 5: val_loss did not improve from 0.33382\n",
      "84/84 [==============================] - 38s 449ms/step - loss: 0.1138 - accuracy: 0.9705 - val_loss: 0.4642 - val_accuracy: 0.8235\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9661\n",
      "Epoch 6: val_loss did not improve from 0.33382\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 0.1241 - accuracy: 0.9661 - val_loss: 0.3371 - val_accuracy: 0.8431\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9657\n",
      "Epoch 7: val_loss did not improve from 0.33382\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.1271 - accuracy: 0.9657 - val_loss: 0.3906 - val_accuracy: 0.7647\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9646\n",
      "Epoch 8: val_loss did not improve from 0.33382\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.1301 - accuracy: 0.9646 - val_loss: 0.5173 - val_accuracy: 0.7451\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9679\n",
      "Epoch 9: val_loss did not improve from 0.33382\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 0.1244 - accuracy: 0.9679 - val_loss: 0.6522 - val_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9635\n",
      "Epoch 10: val_loss did not improve from 0.33382\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 0.1234 - accuracy: 0.9635 - val_loss: 0.5935 - val_accuracy: 0.8039\n",
      "Learning rate for this round is: 0.0001\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9676\n",
      "Epoch 1: val_loss improved from inf to 0.43399, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 441ms/step - loss: 0.1251 - accuracy: 0.9676 - val_loss: 0.4340 - val_accuracy: 0.8039\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9735\n",
      "Epoch 2: val_loss did not improve from 0.43399\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 0.1027 - accuracy: 0.9735 - val_loss: 0.4661 - val_accuracy: 0.7647\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9705\n",
      "Epoch 3: val_loss improved from 0.43399 to 0.41091, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 0.1080 - accuracy: 0.9705 - val_loss: 0.4109 - val_accuracy: 0.7843\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9713\n",
      "Epoch 4: val_loss improved from 0.41091 to 0.36625, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 0.1106 - accuracy: 0.9713 - val_loss: 0.3663 - val_accuracy: 0.7843\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9691\n",
      "Epoch 5: val_loss did not improve from 0.36625\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 0.1093 - accuracy: 0.9691 - val_loss: 0.4414 - val_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9705\n",
      "Epoch 6: val_loss did not improve from 0.36625\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 0.1061 - accuracy: 0.9705 - val_loss: 0.3767 - val_accuracy: 0.7843\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9735\n",
      "Epoch 7: val_loss did not improve from 0.36625\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 0.1050 - accuracy: 0.9735 - val_loss: 0.3687 - val_accuracy: 0.7843\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9765\n",
      "Epoch 8: val_loss did not improve from 0.36625\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.0986 - accuracy: 0.9765 - val_loss: 0.4028 - val_accuracy: 0.7843\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9739\n",
      "Epoch 9: val_loss improved from 0.36625 to 0.33556, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.1027 - accuracy: 0.9739 - val_loss: 0.3356 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9732\n",
      "Epoch 10: val_loss did not improve from 0.33556\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 0.1046 - accuracy: 0.9732 - val_loss: 0.3706 - val_accuracy: 0.7843\n",
      "Learning rate for this round is: 0.0001\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9750\n",
      "Epoch 1: val_loss improved from inf to 0.33689, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.0963 - accuracy: 0.9750 - val_loss: 0.3369 - val_accuracy: 0.8627\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9754\n",
      "Epoch 2: val_loss did not improve from 0.33689\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 0.0978 - accuracy: 0.9754 - val_loss: 0.3695 - val_accuracy: 0.8235\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9732\n",
      "Epoch 3: val_loss did not improve from 0.33689\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 0.0968 - accuracy: 0.9732 - val_loss: 0.4210 - val_accuracy: 0.8039\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9713\n",
      "Epoch 4: val_loss did not improve from 0.33689\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 0.1009 - accuracy: 0.9713 - val_loss: 0.3692 - val_accuracy: 0.7647\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9761\n",
      "Epoch 5: val_loss improved from 0.33689 to 0.31928, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.0907 - accuracy: 0.9761 - val_loss: 0.3193 - val_accuracy: 0.8431\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9735\n",
      "Epoch 6: val_loss did not improve from 0.31928\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.0956 - accuracy: 0.9735 - val_loss: 0.3541 - val_accuracy: 0.7843\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9705\n",
      "Epoch 7: val_loss did not improve from 0.31928\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.0966 - accuracy: 0.9705 - val_loss: 0.3361 - val_accuracy: 0.8235\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9668\n",
      "Epoch 8: val_loss did not improve from 0.31928\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 0.1075 - accuracy: 0.9668 - val_loss: 0.3410 - val_accuracy: 0.7843\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9724\n",
      "Epoch 9: val_loss did not improve from 0.31928\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.0932 - accuracy: 0.9724 - val_loss: 0.3518 - val_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9732\n",
      "Epoch 10: val_loss did not improve from 0.31928\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 0.0982 - accuracy: 0.9732 - val_loss: 0.3990 - val_accuracy: 0.7843\n",
      "Updated accuracy after using 1 augmented training datasets: 78.43\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9512\n",
      "Epoch 1: val_loss improved from inf to 0.34064, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 39s 450ms/step - loss: 0.1755 - accuracy: 0.9512 - val_loss: 0.3406 - val_accuracy: 0.8824\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.9571\n",
      "Epoch 2: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 38s 454ms/step - loss: 0.4119 - accuracy: 0.9571 - val_loss: 0.9952 - val_accuracy: 0.8235\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.9433\n",
      "Epoch 3: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 44s 527ms/step - loss: 0.5476 - accuracy: 0.9433 - val_loss: 0.8250 - val_accuracy: 0.7647\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.9530\n",
      "Epoch 4: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 0.3743 - accuracy: 0.9530 - val_loss: 0.5584 - val_accuracy: 0.8431\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.9489\n",
      "Epoch 5: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.3465 - accuracy: 0.9489 - val_loss: 0.7720 - val_accuracy: 0.8039\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.9478\n",
      "Epoch 6: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 0.3215 - accuracy: 0.9478 - val_loss: 0.5017 - val_accuracy: 0.8431\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.9534\n",
      "Epoch 7: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 0.3919 - accuracy: 0.9534 - val_loss: 0.6662 - val_accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.9497\n",
      "Epoch 8: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 0.3631 - accuracy: 0.9497 - val_loss: 0.5141 - val_accuracy: 0.8235\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.9515\n",
      "Epoch 9: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.3841 - accuracy: 0.9515 - val_loss: 0.6511 - val_accuracy: 0.9020\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.9485\n",
      "Epoch 10: val_loss did not improve from 0.34064\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.3897 - accuracy: 0.9485 - val_loss: 0.4325 - val_accuracy: 0.8431\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9564\n",
      "Epoch 1: val_loss improved from inf to 0.62207, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 437ms/step - loss: 0.2552 - accuracy: 0.9564 - val_loss: 0.6221 - val_accuracy: 0.8039\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9426\n",
      "Epoch 2: val_loss did not improve from 0.62207\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.2685 - accuracy: 0.9426 - val_loss: 1.9101 - val_accuracy: 0.6078\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.9545\n",
      "Epoch 3: val_loss improved from 0.62207 to 0.40077, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 0.2564 - accuracy: 0.9545 - val_loss: 0.4008 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.9452\n",
      "Epoch 4: val_loss did not improve from 0.40077\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 0.2584 - accuracy: 0.9452 - val_loss: 0.5159 - val_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9530\n",
      "Epoch 5: val_loss improved from 0.40077 to 0.37382, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 0.2266 - accuracy: 0.9530 - val_loss: 0.3738 - val_accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9538\n",
      "Epoch 6: val_loss did not improve from 0.37382\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.2241 - accuracy: 0.9538 - val_loss: 0.3910 - val_accuracy: 0.8824\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9564\n",
      "Epoch 7: val_loss improved from 0.37382 to 0.32864, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 0.2232 - accuracy: 0.9564 - val_loss: 0.3286 - val_accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.9489\n",
      "Epoch 8: val_loss did not improve from 0.32864\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.2267 - accuracy: 0.9489 - val_loss: 0.8840 - val_accuracy: 0.6275\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.9549\n",
      "Epoch 9: val_loss did not improve from 0.32864\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 0.2095 - accuracy: 0.9549 - val_loss: 0.4450 - val_accuracy: 0.8431\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.9497\n",
      "Epoch 10: val_loss did not improve from 0.32864\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 0.2123 - accuracy: 0.9497 - val_loss: 1.7929 - val_accuracy: 0.5686\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9534\n",
      "Epoch 1: val_loss improved from inf to 0.51558, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 40s 462ms/step - loss: 0.1933 - accuracy: 0.9534 - val_loss: 0.5156 - val_accuracy: 0.7843\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9620\n",
      "Epoch 2: val_loss improved from 0.51558 to 0.43426, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 39s 467ms/step - loss: 0.1942 - accuracy: 0.9620 - val_loss: 0.4343 - val_accuracy: 0.8039\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.9545\n",
      "Epoch 3: val_loss did not improve from 0.43426\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 0.2041 - accuracy: 0.9545 - val_loss: 0.8920 - val_accuracy: 0.6863\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.9500\n",
      "Epoch 4: val_loss did not improve from 0.43426\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 0.2144 - accuracy: 0.9500 - val_loss: 0.6777 - val_accuracy: 0.6471\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9534\n",
      "Epoch 5: val_loss did not improve from 0.43426\n",
      "84/84 [==============================] - 38s 446ms/step - loss: 0.2171 - accuracy: 0.9534 - val_loss: 0.7236 - val_accuracy: 0.7255\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9567\n",
      "Epoch 6: val_loss did not improve from 0.43426\n",
      "84/84 [==============================] - 44s 522ms/step - loss: 0.2048 - accuracy: 0.9567 - val_loss: 0.9797 - val_accuracy: 0.7255\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.9538\n",
      "Epoch 7: val_loss did not improve from 0.43426\n",
      "84/84 [==============================] - 46s 550ms/step - loss: 0.2058 - accuracy: 0.9538 - val_loss: 0.4909 - val_accuracy: 0.8235\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9556\n",
      "Epoch 8: val_loss did not improve from 0.43426\n",
      "84/84 [==============================] - 39s 457ms/step - loss: 0.2071 - accuracy: 0.9556 - val_loss: 0.6890 - val_accuracy: 0.7451\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9541\n",
      "Epoch 9: val_loss improved from 0.43426 to 0.34474, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 0.2003 - accuracy: 0.9541 - val_loss: 0.3447 - val_accuracy: 0.8431\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9549\n",
      "Epoch 10: val_loss did not improve from 0.34474\n",
      "84/84 [==============================] - 38s 445ms/step - loss: 0.2141 - accuracy: 0.9549 - val_loss: 0.6367 - val_accuracy: 0.7843\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9553\n",
      "Epoch 1: val_loss improved from inf to 0.62345, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 39s 450ms/step - loss: 0.1978 - accuracy: 0.9553 - val_loss: 0.6234 - val_accuracy: 0.7451\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9582\n",
      "Epoch 2: val_loss did not improve from 0.62345\n",
      "84/84 [==============================] - 38s 455ms/step - loss: 0.1896 - accuracy: 0.9582 - val_loss: 0.8257 - val_accuracy: 0.6471\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9579\n",
      "Epoch 3: val_loss did not improve from 0.62345\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 0.1933 - accuracy: 0.9579 - val_loss: 1.0295 - val_accuracy: 0.6471\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9545\n",
      "Epoch 4: val_loss improved from 0.62345 to 0.39382, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.2079 - accuracy: 0.9545 - val_loss: 0.3938 - val_accuracy: 0.8431\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9582\n",
      "Epoch 5: val_loss did not improve from 0.39382\n",
      "84/84 [==============================] - 37s 434ms/step - loss: 0.1888 - accuracy: 0.9582 - val_loss: 0.9623 - val_accuracy: 0.5686\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9545\n",
      "Epoch 6: val_loss did not improve from 0.39382\n",
      "84/84 [==============================] - 37s 433ms/step - loss: 0.1946 - accuracy: 0.9545 - val_loss: 0.6091 - val_accuracy: 0.7843\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9556\n",
      "Epoch 7: val_loss did not improve from 0.39382\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 0.2014 - accuracy: 0.9556 - val_loss: 0.9093 - val_accuracy: 0.7059\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9590\n",
      "Epoch 8: val_loss did not improve from 0.39382\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.1886 - accuracy: 0.9590 - val_loss: 0.5355 - val_accuracy: 0.8431\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9549\n",
      "Epoch 9: val_loss did not improve from 0.39382\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.1951 - accuracy: 0.9549 - val_loss: 0.4742 - val_accuracy: 0.8039\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.9646\n",
      "Epoch 10: val_loss did not improve from 0.39382\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 0.1737 - accuracy: 0.9646 - val_loss: 0.5675 - val_accuracy: 0.7647\n",
      "Learning rate for this round is: 0.002\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.9571\n",
      "Epoch 1: val_loss improved from inf to 0.92674, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 424ms/step - loss: 0.1862 - accuracy: 0.9571 - val_loss: 0.9267 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.9556\n",
      "Epoch 2: val_loss did not improve from 0.92674\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.1843 - accuracy: 0.9556 - val_loss: 1.6351 - val_accuracy: 0.5882\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9631\n",
      "Epoch 3: val_loss improved from 0.92674 to 0.63401, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.1700 - accuracy: 0.9631 - val_loss: 0.6340 - val_accuracy: 0.6863\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9609\n",
      "Epoch 4: val_loss improved from 0.63401 to 0.41621, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.1743 - accuracy: 0.9609 - val_loss: 0.4162 - val_accuracy: 0.8431\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9623\n",
      "Epoch 5: val_loss did not improve from 0.41621\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 0.1754 - accuracy: 0.9623 - val_loss: 0.6027 - val_accuracy: 0.7647\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9616\n",
      "Epoch 6: val_loss improved from 0.41621 to 0.33743, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.1825 - accuracy: 0.9616 - val_loss: 0.3374 - val_accuracy: 0.9020\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9575\n",
      "Epoch 7: val_loss did not improve from 0.33743\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 0.1964 - accuracy: 0.9575 - val_loss: 0.7072 - val_accuracy: 0.7647\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9638\n",
      "Epoch 8: val_loss did not improve from 0.33743\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 0.1850 - accuracy: 0.9638 - val_loss: 0.7113 - val_accuracy: 0.7255\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9601\n",
      "Epoch 9: val_loss did not improve from 0.33743\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.1842 - accuracy: 0.9601 - val_loss: 1.8125 - val_accuracy: 0.4510\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.9582\n",
      "Epoch 10: val_loss did not improve from 0.33743\n",
      "84/84 [==============================] - 38s 455ms/step - loss: 0.2000 - accuracy: 0.9582 - val_loss: 0.5903 - val_accuracy: 0.8039\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9657\n",
      "Epoch 1: val_loss improved from inf to 0.48095, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 44s 512ms/step - loss: 0.1535 - accuracy: 0.9657 - val_loss: 0.4810 - val_accuracy: 0.8235\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9683\n",
      "Epoch 2: val_loss improved from 0.48095 to 0.30232, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 0.1540 - accuracy: 0.9683 - val_loss: 0.3023 - val_accuracy: 0.8824\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9679\n",
      "Epoch 3: val_loss did not improve from 0.30232\n",
      "84/84 [==============================] - 35s 418ms/step - loss: 0.1298 - accuracy: 0.9679 - val_loss: 0.3228 - val_accuracy: 0.8431\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9709\n",
      "Epoch 4: val_loss did not improve from 0.30232\n",
      "84/84 [==============================] - 35s 418ms/step - loss: 0.1333 - accuracy: 0.9709 - val_loss: 0.4653 - val_accuracy: 0.7647\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9691\n",
      "Epoch 5: val_loss improved from 0.30232 to 0.20422, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 0.1295 - accuracy: 0.9691 - val_loss: 0.2042 - val_accuracy: 0.9216\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9732\n",
      "Epoch 6: val_loss did not improve from 0.20422\n",
      "84/84 [==============================] - 35s 418ms/step - loss: 0.1157 - accuracy: 0.9732 - val_loss: 0.6058 - val_accuracy: 0.7451\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9728\n",
      "Epoch 7: val_loss did not improve from 0.20422\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.1145 - accuracy: 0.9728 - val_loss: 0.3153 - val_accuracy: 0.8235\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9758\n",
      "Epoch 8: val_loss did not improve from 0.20422\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.1077 - accuracy: 0.9758 - val_loss: 0.5404 - val_accuracy: 0.8431\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9735\n",
      "Epoch 9: val_loss did not improve from 0.20422\n",
      "84/84 [==============================] - 452s 5s/step - loss: 0.1116 - accuracy: 0.9735 - val_loss: 0.4181 - val_accuracy: 0.8627\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9732\n",
      "Epoch 10: val_loss did not improve from 0.20422\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 0.1163 - accuracy: 0.9732 - val_loss: 0.3103 - val_accuracy: 0.9020\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.9750\n",
      "Epoch 1: val_loss improved from inf to 0.32857, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 418ms/step - loss: 0.1082 - accuracy: 0.9750 - val_loss: 0.3286 - val_accuracy: 0.8627\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9724\n",
      "Epoch 2: val_loss did not improve from 0.32857\n",
      "84/84 [==============================] - 35s 413ms/step - loss: 0.1084 - accuracy: 0.9724 - val_loss: 0.4750 - val_accuracy: 0.8039\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9743\n",
      "Epoch 3: val_loss did not improve from 0.32857\n",
      "84/84 [==============================] - 35s 416ms/step - loss: 0.1021 - accuracy: 0.9743 - val_loss: 0.4600 - val_accuracy: 0.8627\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9717\n",
      "Epoch 4: val_loss did not improve from 0.32857\n",
      "84/84 [==============================] - 44s 520ms/step - loss: 0.1081 - accuracy: 0.9717 - val_loss: 0.3444 - val_accuracy: 0.8235\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9761\n",
      "Epoch 5: val_loss did not improve from 0.32857\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 0.1037 - accuracy: 0.9761 - val_loss: 0.4067 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9709\n",
      "Epoch 6: val_loss improved from 0.32857 to 0.26174, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 422ms/step - loss: 0.1093 - accuracy: 0.9709 - val_loss: 0.2617 - val_accuracy: 0.9216\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9773\n",
      "Epoch 7: val_loss improved from 0.26174 to 0.21457, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 421ms/step - loss: 0.0904 - accuracy: 0.9773 - val_loss: 0.2146 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9758\n",
      "Epoch 8: val_loss did not improve from 0.21457\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.1000 - accuracy: 0.9758 - val_loss: 0.4358 - val_accuracy: 0.8235\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9720\n",
      "Epoch 9: val_loss did not improve from 0.21457\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.1005 - accuracy: 0.9720 - val_loss: 0.2842 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 0.9739\n",
      "Epoch 10: val_loss did not improve from 0.21457\n",
      "84/84 [==============================] - 35s 418ms/step - loss: 0.1047 - accuracy: 0.9739 - val_loss: 0.2422 - val_accuracy: 0.9216\n",
      "Learning rate for this round is: 0.0005\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9720\n",
      "Epoch 1: val_loss improved from inf to 0.39694, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 424ms/step - loss: 0.1017 - accuracy: 0.9720 - val_loss: 0.3969 - val_accuracy: 0.8431\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9750\n",
      "Epoch 2: val_loss did not improve from 0.39694\n",
      "84/84 [==============================] - 35s 419ms/step - loss: 0.0890 - accuracy: 0.9750 - val_loss: 0.5929 - val_accuracy: 0.7843\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9709\n",
      "Epoch 3: val_loss improved from 0.39694 to 0.28982, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 0.0986 - accuracy: 0.9709 - val_loss: 0.2898 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9791\n",
      "Epoch 4: val_loss did not improve from 0.28982\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.0934 - accuracy: 0.9791 - val_loss: 0.3465 - val_accuracy: 0.8627\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9720\n",
      "Epoch 5: val_loss did not improve from 0.28982\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 0.1007 - accuracy: 0.9720 - val_loss: 0.3411 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9776\n",
      "Epoch 6: val_loss did not improve from 0.28982\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 0.0927 - accuracy: 0.9776 - val_loss: 0.3432 - val_accuracy: 0.8431\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9761\n",
      "Epoch 7: val_loss improved from 0.28982 to 0.27940, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.0948 - accuracy: 0.9761 - val_loss: 0.2794 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9810\n",
      "Epoch 8: val_loss did not improve from 0.27940\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 0.0933 - accuracy: 0.9810 - val_loss: 0.2892 - val_accuracy: 0.8627\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9713\n",
      "Epoch 9: val_loss did not improve from 0.27940\n",
      "84/84 [==============================] - 36s 421ms/step - loss: 0.0986 - accuracy: 0.9713 - val_loss: 0.4189 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9754\n",
      "Epoch 10: val_loss did not improve from 0.27940\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 0.0948 - accuracy: 0.9754 - val_loss: 0.2817 - val_accuracy: 0.8824\n",
      "Learning rate for this round is: 0.0001\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9773\n",
      "Epoch 1: val_loss improved from inf to 0.20358, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 37s 426ms/step - loss: 0.0935 - accuracy: 0.9773 - val_loss: 0.2036 - val_accuracy: 0.9020\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9791\n",
      "Epoch 2: val_loss did not improve from 0.20358\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 0.0880 - accuracy: 0.9791 - val_loss: 0.2072 - val_accuracy: 0.9020\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9795\n",
      "Epoch 3: val_loss improved from 0.20358 to 0.19678, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 0.0882 - accuracy: 0.9795 - val_loss: 0.1968 - val_accuracy: 0.9020\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9810\n",
      "Epoch 4: val_loss did not improve from 0.19678\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 0.1978 - val_accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9799\n",
      "Epoch 5: val_loss improved from 0.19678 to 0.18750, saving model to weights.best.inc.blond.hdf5\n",
      "84/84 [==============================] - 36s 423ms/step - loss: 0.0788 - accuracy: 0.9799 - val_loss: 0.1875 - val_accuracy: 0.9412\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9750\n",
      "Epoch 6: val_loss did not improve from 0.18750\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 0.0880 - accuracy: 0.9750 - val_loss: 0.2142 - val_accuracy: 0.9020\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9761\n",
      "Epoch 7: val_loss did not improve from 0.18750\n",
      "84/84 [==============================] - 35s 420ms/step - loss: 0.0881 - accuracy: 0.9761 - val_loss: 0.2126 - val_accuracy: 0.9020\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9750\n",
      "Epoch 8: val_loss did not improve from 0.18750\n",
      "84/84 [==============================] - 35s 421ms/step - loss: 0.0871 - accuracy: 0.9750 - val_loss: 0.1876 - val_accuracy: 0.9608\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9758\n",
      "Epoch 9: val_loss did not improve from 0.18750\n",
      "84/84 [==============================] - 47s 561ms/step - loss: 0.0894 - accuracy: 0.9758 - val_loss: 0.1917 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9802\n",
      "Epoch 10: val_loss did not improve from 0.18750\n",
      "84/84 [==============================] - 35s 418ms/step - loss: 0.0727 - accuracy: 0.9802 - val_loss: 0.2227 - val_accuracy: 0.9020\n",
      "Updated accuracy after using 2 augmented training datasets: 90.2\n"
     ]
    }
   ],
   "source": [
    "training_history: Dict[str, List[float]] = {}\n",
    "for his_key in ('loss', 'accuracy', 'val_loss', 'val_accuracy'):\n",
    "    training_history[his_key] = [] \n",
    "\n",
    "acc_per_100_epochs: List[float] = []\n",
    "\n",
    "# first 50% epochs: 2e-3, 50%-80% epochs: 5e-4, 80%-100% epochs: 1e-4\n",
    "def obtain_lr(initial_lr: float, total_epochs: int, round_index: int, epochs_per_round: int) -> float:\n",
    "    assert total_epochs>=10 and total_epochs%10==0, \"The number of datasets must be divsible by 10!\"\n",
    "    assert 0<(round_index*epochs_per_round)<=total_epochs\n",
    "    return initial_lr if round_index*epochs_per_round<=total_epochs/2 else initial_lr/4 if round_index*epochs_per_round<=total_epochs*0.8 else initial_lr/20\n",
    "\n",
    "# 100 epochs for each augmented dataset, maximally 500 epochs, stop training when the average validation accuracy of last 10 epochs becomes above 0.9\n",
    "stop_training: bool = False\n",
    "rounds_per_dataset: int = 10\n",
    "for dataset_count in range(1, 6):\n",
    "    if stop_training: break\n",
    "    for round_count in range(1, rounds_per_dataset+1):\n",
    "        lr = obtain_lr(2e-3, 100, round_count, 10)\n",
    "        print(f'Learning rate for this round is: {str(lr)}')\n",
    "        own_model, history = fitted_own_model(own_model, lr, train_iterator, test_iterator)\n",
    "        for his_key in history.history.keys():\n",
    "            training_history[his_key].extend(history.history[his_key])\n",
    "        sliding_avg_10_acc: float = mean(training_history['val_accuracy'][-10:])\n",
    "        if sliding_avg_10_acc > 0.9: \n",
    "            stop_training = True   \n",
    "            break\n",
    "    acc = own_model.evaluate(test_iterator, verbose=0)[1]\n",
    "    print(f\"Updated accuracy after using {str(dataset_count)} augmented training datasets: {round(acc, 4)*100}\")\n",
    "    own_model.save(\"pneumonia_aug_self_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2128d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trained epochs until we obtained an accuracy > 90%: 190\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of trained epochs until we obtained an accuracy > 90%: {len(training_history['val_accuracy'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2ad42c12d432d7a62533328dc0e292756d70a954dbe4d208dd019bb5f886e15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
